{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LpnEVMCYYlnD"
      },
      "source": [
        "# Νευρωνικά Δίκτυα και Βαθιά Μάθηση\n",
        "\n",
        "## Φώτιος Κούτσικος\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cc_H7oqS1Zjz"
      },
      "source": [
        "# Μέρος Α: Fine-tune a pretrained model\n",
        "\n",
        "Τα γλωσσικά μοντέλα αποτελούνται από δύο στάδια εκπαίδευσης:\n",
        "1. **Pre-training σε μεγάλα unlabelled datasets**:\n",
        "\n",
        "  Το pre-training είναι υπολογιστικά πολύ ακριβό και γι αυτό στην πράξη δε το χρησιμοποιούμε όταν θέλουμε να τρέξουμε ένα μοντέλο σε ένα καινούργιο dataset. Μπορούμε να σκεφτούμε το pre-training ως τη διαδικασία εκμάθησης γλωσσικών κανόνων κι εννοιών, οι οποίες στη συνέχεια μπορούν να χρησιμοποιηθούν για διάφορους σκοπούς.\n",
        "\n",
        "2. **Fine-tuning σε μικρότερα labelled datasets**:\n",
        "  \n",
        "     Το fine-tuning πρακτικά εκμεταλλεύεται τις ιδιότητες του transfer learning προκειμένου να μεταφέρουμε τη 'γνώση' που έχει αποθηκευθεί στο γλωσσικό μοντέλο κατά τη διάρκεια του pre-training σε συγκεκριμένα task. Κάθε task εξυπηρετείται μέσω στοχευμένων datasets. Για παράδειγμα, κάποια datasets αναφέρονται στην ταξινόμηση κειμένων σε κατηγιορίες (text classification), άλλα datasets περιέχουν ερωτήσεις οι οποίες πρέπει να απαντηθούν (question answering) κι άλλα πολλά.\n",
        "\n",
        "Κάποια κλασικά tasks της επεξεργασίας φυσικής γλώσσας είναι τα ακόλουθα:\n",
        "- Text classification\n",
        "- Question answering\n",
        "- Natural language inference\n",
        "- Fill mask\n",
        "- Semantic similarity\n",
        "\n",
        "Περισσότερες πληροφορίες μπορείτε να βρείτε στον ακόλουθο σύνδεσμο στο domain Natural Language Processing: https://huggingface.co/models\n",
        "\n",
        "Στο πρώτο κομμάτι της παρούσας εργαστηριακής άσκησης, θα χρησιμοποιήσουμε το pre-training fine-tuning σενάριο για να ταξινομήσουμε reviews."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-KvTKunnp0v"
      },
      "source": [
        "## Pipelines\n",
        "\n",
        "Με τη χρήση του **text-classification pipeline** μπορούμε να τρέξουμε γλωσσικά μοντέλα που αφορούν tasks ταξινόμησης.\n",
        "\n",
        "Το natural language inference (NLI) task αποτελεί ένα task ταξινόμησης, αφού το σχετικό μοντέλο (εν προκειμένω το roberta-large-mnli) καλείται να ταξινομήσει ένα κείμενο σε μία από τις 3 κατηγορίες: **[entailment/neutral/contradiction]**.\n",
        "\n",
        "```\n",
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline(\"text-classification\", model = \"roberta-large-mnli\")\n",
        "classifier(\"A soccer game with multiple males playing. Some men are playing a sport.\")\n",
        "## [{'label': 'ENTAILMENT', 'score': 0.98}]\n",
        "```\n",
        "\n",
        "Ένα άλλο task ταξινόμησης αφορά την αξιολόγηση του κατά πόσο ένα κείμενο είναι **γραμματικά ορθό (acceptable) ή όχι (unacceptable)**:\n",
        "\n",
        "```\n",
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline(\"text-classification\", model = \"textattack/distilbert-base-uncased-CoLA\")\n",
        "classifier(\"I will walk to home when I went through the bus.\")\n",
        "##  [{'label': 'unacceptable', 'score': 0.95}]\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2UxEv7x1Zj1"
      },
      "source": [
        "## Σύνολο δεδομένων Yelp polarity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTNsahTl1Zj2"
      },
      "source": [
        "Κατεβάζουμε το [Yelp Polarity](https://huggingface.co/datasets/yelp_polarity) dataset το οποίο περιέχει reviews που εκφράζουν συναισθήματα πελατών για εστιατόρια.\n",
        "Το  Yelp κατασκευάστηκε θεωρώντας τα αστέρια 1 και 2 αρνητικά και τα 3 και 4 θετικά.  Η αρνητική πολικότητα ανήκει στην κατηγορία 1 και η θετική στην κατηγορία 2. Τα reviews αυτά χωρίζονται σε αυτές τις κατηγορίες, και ο σκοπός μας είναι να κατηγοριοποιήσουμε νέα reviews στις σωστές κατηγορίες.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177,
          "referenced_widgets": [
            "b644ca24eceb4395a5c2dfc4f6cabb08",
            "90047d7b824e4a4d8c805c306d9f06e5",
            "105181d8e7b647a6952761d3ee298164",
            "807881518c194479bb97f3545d20ff09",
            "e8a1ec2cb0494626829ea01b5c8e7c60",
            "334691f254ff41bd89624f5b58e88bb3",
            "47aa37adf61c4dd79b933ca4f391385f",
            "8be22023708d4838b4f12001d3a9ea41",
            "4b266826714244caba131f51ceb89af2",
            "5f24a2eeddb1492fafb30c97bc07bcf7",
            "f9671c9b008c48ac8da5de272a8d4a29",
            "5d1fe81ee63640399e0466fe28dc3dbe",
            "c0589ae70e5444e8a65bc73a266223ef",
            "edde5a90c3394ba184885c852978e6d6",
            "addb09a99c8c418a82b15a6996e65549",
            "09ec070a4d72499f8776eb68cd4d584d",
            "eed5b52a23e84261ae26d20543da13b1",
            "657465c0c14648fab901dd22fafb717d",
            "708de9ddf7bd4cd08cfe85c052582008",
            "b5f97ce43f06445c9dca2029e09b8d94",
            "862db87251ed4f318fc937ec2b805f62",
            "0912fd94f9504d1bb3ccdf672ad859b9",
            "50b992cff4a3470aa44cd015114445b2",
            "153ad800228d45f3bebb0cabdc098730",
            "522033f3966948168a629f1c89a4deee",
            "0ce99983d1944a1eafc980d583c0c628",
            "a479b6ea42024f799bd751453b6fbfd7",
            "14da5c80a2b04226a7f057f898a0ae9d",
            "7425f5e2ffd94524a4a3c713cb2b1df4",
            "7cbbf25f0ec7471bbd741d83dbf60851",
            "26a3d8662ff64ea29483997fa478d432",
            "3e80cd5a3bf847f79cb478af88203e5a",
            "21130f24c0414209bd012dce7bf85f94",
            "dbaff18d067a424fa4bb3a626cc81453",
            "7017735ef8344e5fb64b041e0e2a062f",
            "f55d358e0d7747ac8f353ed55496555c",
            "e3f24fa01d47405f896c6e5c705c7aac",
            "69aa7136bce74f9399d03c7631526923",
            "01afd9c3197d4971b852793c7ffe91db",
            "9054f0c75bfc4273a4fc3870213e17d1",
            "cc0aec92543b46bebea5944522541403",
            "a564dfcbf0154f1bad8d7405556cc230",
            "4ed9082890ff41df85f1ccbf426679d6",
            "46bfe86636744c86bc4ff203e6d65a88",
            "bba985a21a9d41b7b480a441e71c4d72",
            "f2ecea7ec5ff4a288575fc6f55ffd56b",
            "177d868e93414054954d145e8aad97e2",
            "5876644917da46c69fb5667bbf3aae39",
            "82aca72ef37a4d28ad83aba2073f54ab",
            "e56c80cfb74c4466981a2254adf74a23",
            "9cf53e0140474b6a904ac41198a7111d",
            "07675bc1554b4fd9aece2e88f444ef10",
            "ec43300954f54120b42ec00e62295e8f",
            "a5d727af0b104e9fbd4af531210754ce",
            "bfabb8d784a047149e14938702352b16"
          ]
        },
        "id": "uS3fgJzzNBQL",
        "outputId": "769d09f5-9f4e-4f4c-aa6f-82c22f6d3827"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b644ca24eceb4395a5c2dfc4f6cabb08",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md:   0%|          | 0.00/8.93k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5d1fe81ee63640399e0466fe28dc3dbe",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "train-00000-of-00001.parquet:   0%|          | 0.00/256M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "50b992cff4a3470aa44cd015114445b2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "test-00000-of-00001.parquet:   0%|          | 0.00/17.7M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dbaff18d067a424fa4bb3a626cc81453",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/560000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bba985a21a9d41b7b480a441e71c4d72",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating test split:   0%|          | 0/38000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from datasets import load_dataset, concatenate_datasets\n",
        "import numpy as np\n",
        "\n",
        "# insert your code here\n",
        "dataset = load_dataset(\"yelp_polarity\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hEzVNuLWzm4"
      },
      "source": [
        "Επειδή το σύνολο δεδομένων του Yelp Polarity περιέχει πολλά δείγματα, προκειμένου να επιταχύνουμε τη διαδικασία του fine-tuning συστήνεται να διατηρούμε 300 δείγματα από το train set και 300 δείγματα από το test set.\n",
        "\n",
        "Ελέγχουμε τον αριθμό κατηγοριών που υπάρχουν συνολικά στο train και το test set και διατηρούμε ισορροπημένο αριθμό δειγμάτων ανά κατηγορία για τα σύνολα αυτά κατά την επιλογή των 300 δειγμάτων."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E2KMyziKHN4R",
        "outputId": "05032d2e-6b15-4d4c-cba2-b1becc846236"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'text': \"Unfortunately, the frustration of being Dr. Goldberg's patient is a repeat of the experience I've had with so many other doctors in NYC -- good doctor, terrible staff.  It seems that his staff simply never answers the phone.  It usually takes 2 hours of repeated calling to get an answer.  Who has time for that or wants to deal with it?  I have run into this problem with many other doctors and I just don't get it.  You have office workers, you have patients with medical needs, why isn't anyone answering the phone?  It's incomprehensible and not work the aggravation.  It's with regret that I feel that I have to give Dr. Goldberg 2 stars.\",\n",
              " 'label': 0}"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset[\"train\"][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353,
          "referenced_widgets": [
            "21b5790177164ff48b97f130d59247b3",
            "119dbcd1a80a469990e78fa901d38957",
            "b1a5773aad424e1494f4bcc2eedd9fb1",
            "70ab6f7e7728487592d1211ebc2660a1",
            "0b14aa7b5b8d46da8274ddfd0262bf89",
            "907a43571224440ea4aafe4902de67a4",
            "b58ac70d13c14dbe8bef8b5c212bb231",
            "6e0de74ab1fb43bb88214cb4a035ac14",
            "cc800e0b26aa47c58d5ffa6e9de3f2cb",
            "1da42017c536400ca866dd8b0c5fc2eb",
            "1be6c8413b4b4ce39f978fa1de771c3c",
            "8f5c2dad76e145d1815fe10b962c0b76",
            "c2c34278b19644ab8c415fba7618c3f3",
            "e3336264952d4b99a24d54d323238d86",
            "30af51d243594776999cf2581f89bea3",
            "7b9d5e09557e416b80a893866efbbc6e",
            "d53ac9c3b4f3449a8fe7a4076f7f3ae5",
            "b7772469ecb04d38bccc2ba989554bca",
            "04c3caf74d184d469324fa6207f9b7c0",
            "22f74749c1be4429bf5c3b6443f5c88e",
            "93b75fe9a45b4557b0f1307014ef7c56",
            "62110964115648aead7c93474e6bd0ad",
            "927f3c34b04d45d29dbbbe1f01d77bc3",
            "21dccb8a20224b129146db7a8a69aad9",
            "13f502b481304ae3bfd3bf988c22960a",
            "1b356873b9114265b1ac66ed05011cc7",
            "6e4fdd641f834ff285bcc95db89d916f",
            "c2f4469146ea4c13baf2b9b0873802fd",
            "e23765a3f1bb483581b1b534e2ff559d",
            "9c88c1d947f94c4896887907ffef0d0b",
            "d14d34944c8c4f7d887f58134ec6462e",
            "2a0d115b924842798cc1d2692c83cade",
            "208d99f37bd0400dbffc140617f27789",
            "4c04b121eef441168b2d21557730cad6",
            "a5f5ab0cf34c4a43a2c9826367286e00",
            "d886f21d67674978be9a8b5dccc1917b",
            "61bffdca755440a7b8c5809184694def",
            "8a52991bdf08451084830e3a50ba9361",
            "d4a7f1c1fcc241efb090d1d9769c64c9",
            "5cc7d42274ba4162b7ea77be62dde13a",
            "8a800facafcf411194293d9bfcb719d7",
            "6e431081c6c4474a8838a77bca7e544e",
            "d77ce6d961bc40c9aa52cbb1ecc1e3ce",
            "97099efade8a4317b15c6af40aa7c74d"
          ]
        },
        "id": "pcLF72ZOxWbJ",
        "outputId": "bb26c868-7886-4bd9-93bb-980db98847f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of positive reviews in the Train Dataset is: 280000\n",
            "The number of negative reviews in the Train Dataset is: 280000\n",
            "\n",
            "The number of positive reviews in the Test Dataset is: 19000\n",
            "The number of negative reviews in the Test Dataset is: 19000\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "21b5790177164ff48b97f130d59247b3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Filter:   0%|          | 0/560000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8f5c2dad76e145d1815fe10b962c0b76",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Filter:   0%|          | 0/560000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "927f3c34b04d45d29dbbbe1f01d77bc3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Filter:   0%|          | 0/38000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4c04b121eef441168b2d21557730cad6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Filter:   0%|          | 0/38000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "The number of positive reviews in the Train Dataset after preprocessing is: 150\n",
            "The number of negative reviews in the Train Dataset after preprocessing is: 150\n",
            "\n",
            "The number of positive reviews in the Test Dataset after preprocessing is: 150\n",
            "The number of negative reviews in the Test Dataset after preprocessing is: 150\n"
          ]
        }
      ],
      "source": [
        "train_dataset = dataset[\"train\"]\n",
        "test_dataset = dataset[\"test\"]\n",
        "\n",
        "\n",
        "print(\"The number of positive reviews in the Train Dataset is:\", train_dataset['label'].count(0))\n",
        "print(\"The number of negative reviews in the Train Dataset is:\", train_dataset['label'].count(1))\n",
        "print()\n",
        "print(\"The number of positive reviews in the Test Dataset is:\", test_dataset['label'].count(0))\n",
        "print(\"The number of negative reviews in the Test Dataset is:\", test_dataset['label'].count(1))\n",
        "print()\n",
        "\n",
        "# We are keeping 300 for each dataset, 150 positive and 150 negative\n",
        "train_remove_pos = 280000 - 150\n",
        "train_remove_neg = 280000 - 150\n",
        "\n",
        "train_pos_ds = train_dataset.filter(lambda example: example['label'] == 1) # Filter for positive reviews\n",
        "train_neg_ds = train_dataset.filter(lambda example: example['label'] == 0) # Filter for negative reviews\n",
        "\n",
        "\n",
        "train_pos_drop_indices = np.random.choice(train_pos_ds.num_rows, train_remove_pos, replace=False)\n",
        "train_neg_drop_indices = np.random.choice(train_neg_ds.num_rows, train_remove_neg, replace=False)\n",
        "\n",
        "train_pos_ds = train_pos_ds.select(np.delete(np.arange(train_pos_ds.num_rows),train_pos_drop_indices)) # Select the remaining positive reviews\n",
        "train_neg_ds = train_neg_ds.select(np.delete(np.arange(train_neg_ds.num_rows),train_neg_drop_indices)) # Select the remaining negative reviews\n",
        "\n",
        "train_dataset = concatenate_datasets([train_pos_ds, train_neg_ds]) # Concatenate the remaining positive and negative reviews\n",
        "\n",
        "# We are doing the same for the test dataset\n",
        "test_remove_pos = 19000 - 150\n",
        "test_remove_neg = 19000 - 150\n",
        "\n",
        "test_pos_ds = test_dataset.filter(lambda example: example['label'] == 1) # Filter for positive reviews\n",
        "test_neg_ds = test_dataset.filter(lambda example: example['label'] == 0) # Filter for negative reviews\n",
        "\n",
        "\n",
        "test_pos_drop_indices = np.random.choice(test_pos_ds.num_rows, test_remove_pos, replace=False)\n",
        "test_neg_drop_indices = np.random.choice(test_neg_ds.num_rows, test_remove_neg, replace=False)\n",
        "\n",
        "test_pos_ds = test_pos_ds.select(np.delete(np.arange(test_pos_ds.num_rows),test_pos_drop_indices)) # Select the remaining positive reviews\n",
        "test_neg_ds = test_neg_ds.select(np.delete(np.arange(test_neg_ds.num_rows),test_neg_drop_indices)) # Select the remaining negative reviews\n",
        "\n",
        "test_dataset = concatenate_datasets([test_pos_ds, test_neg_ds]) # Concatenate the remaining positive and negative reviews\n",
        "\n",
        "print()\n",
        "print(\"The number of positive reviews in the Train Dataset after preprocessing is:\", train_dataset['label'].count(0))\n",
        "print(\"The number of negative reviews in the Train Dataset after preprocessing is:\", train_dataset['label'].count(1))\n",
        "print()\n",
        "print(\"The number of positive reviews in the Test Dataset after preprocessing is:\", test_dataset['label'].count(0))\n",
        "print(\"The number of negative reviews in the Test Dataset after preprocessing is:\", test_dataset['label'].count(1))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-Kj4N9yMaoD",
        "outputId": "484f8070-4219-477f-cffa-ee671fa0659e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['text', 'label'],\n",
              "    num_rows: 300\n",
              "})"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R9RIXrWbONXl",
        "outputId": "8381bd1a-49ea-4532-b18a-94f8ea1aff17"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['text', 'label'],\n",
              "    num_rows: 300\n",
              "})"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3N0xadZjXiIF"
      },
      "source": [
        "# Language Models\n",
        "\n",
        "Η προεπεξεργασία των κειμένων προηγείται της εισόδου τους στα γλωσσικά μοντέλα.\n",
        "\n",
        "Η διαδικασία αυτή επιτελείται μέσω των **Tokenizers**, τα οποία μετατρέπουν τα tokens εισόδου σε κατάλληλα IDs του λεξιλογίου προεκπαίδευσης, κι έτσι μετατρέπουν το κείμενο σε μορφή που μπορεί να επεξεργαστεί κάποιο μοντέλο Transformer. Η βιβλιοθήκη Huggingface προσφέρει εύκολες και high-level υλοποιήσεις tokenization, τις οποίες συστήνεται να ακολουθήσουμε στη συνέχεια.\n",
        "\n",
        "Συγκεκριμένα, **αρχικοποιούμε τη διαδικασία του tokenization με χρήση του AutoTokenizer**. Επιλέγοντας τη μέθοδο **from_pretrained** λαμβάνουμε έναν tokenizer που αποκρίνεται στην αρχιτεκτονική του μοντέλου που επιθυμούμε να χρησιμοποιήσουμε, παρέχοντας συμβατό tokenization.\n",
        "\n",
        "Περισσότερες πληροφορίες για το AutoTokenization μπορείτε να βρείτε εδώ:\n",
        "https://huggingface.co/docs/transformers/model_doc/auto\n",
        "\n",
        "Αναφορικά με το μοντέλο BERT, μπορείτε να δείτε τη διαδικασία [του tokenization και της αρχικοποίησης του μοντέλου](https://huggingface.co/docs/transformers/model_doc/bert#transformers.BertTokenizer):\n",
        "\n",
        "```\n",
        "from transformers import AutoTokenizer, BertModel\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
        "```\n",
        "\n",
        "Στα πλαίσια της άσκησης καλούμαστε να επιτελέσουμε την παραπάνω διαδικασία με *κάποιο άλλο μοντέλο της επιλογής μας από το Huggingface* που να υποστηρίζει τον AutoTokenizer. Το pre-trained μοντέλο που θα επιλέξουμε θα πρέπει να διαθέτει υλοποίηση με sequence classification head (κατ αναλογία της μεθόδου BertForSequenceClassification).\n",
        "\n",
        "Στο επόμενο κελί, φορτώνουμε το επιλεχθέν μοντέλο με τον αντίστοιχο tokenizer.\n",
        "\n",
        "(Αγνοήστε πιθανά warnings της μορφής Some weights of the model checkpoint at xxx were not used when initializing...)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266,
          "referenced_widgets": [
            "9649c74a9b9a437396984b2135aecd39",
            "6df20c3f566a4110b223ee422625e962",
            "08c2222a3c5341cab1b2151687831f6e",
            "3bb2caa210fc45458a7158a08089faf0",
            "ce805590a06240bb808d64d6c102aff8",
            "5c907a4bb0634e4d957849867dc45ecb",
            "96f391f50a414e0d81a1adb0ebeeb7dc",
            "459c022cab72462daae4c1166aadb32b",
            "cc061249c45a4926965b13bc05ae59fd",
            "b0d75aa189fd4053833e0f010af7701e",
            "41e98526187e469bb98d2e4865d14c90",
            "fd6e2d9dfe6b4971b80364a499023d15",
            "fc99e26562f649e8999ede2e49716169",
            "3329163d094a480d99ced6a2a1c755ab",
            "696787c286ef40629ffee2bebaa5bc37",
            "fe4d1bf321ed432cb33b68127f734d90",
            "db9db2b087814f13832494bb42eecb6b",
            "8d33ce23ca024cb285df4fb89f16dec7",
            "f24c4e54f4244d59863eb91f795965bd",
            "5f04f62ce2334e2992b2d2afa4e40b9b",
            "e51d852407a04b44b47b0d27f3e70d2c",
            "b4055ad1932f47799a54ccbc68ab3497",
            "a9e83b168f6c484c8e95e4b98e8a2142",
            "0f62a53da38e4aaab3f2d4e44952e886",
            "a4184fb66ba4472c9d31a25a9c7f8380",
            "531010f8fe904697996065cbee096991",
            "ef2dfcd53c274dd3a0b4383aeb61565b",
            "6538056aa28442a19e1a18cc6baeeb29",
            "147e207266f74ad280fb65f4777babb2",
            "406792eb68c04f63b4d7e1b316c60402",
            "17fa8233c5c143f182419666cdec6e26",
            "48175dd756df4039ab3f51eefc885396",
            "299a41e32d134df1ba1bd3dfffeece0c",
            "6474b8c5d4f54ed4977ae85e43c70e03",
            "55c7c5d7a33646dc8fa13e7b9f26dc0c",
            "e1b1bff3282040ca9342c67ad3670cd3",
            "9a28610fe42e4e81bbe5a139a027b83d",
            "4b9317c9cacc4884b63538ee348ff1e8",
            "7bd774a2ed554fd083b6e1d90336da2b",
            "0933c30139514627abce3b451a4014a8",
            "1b33049401ec4caf9a7ef7eb5ea4b773",
            "7dc443a6c19a4891a90920915f2d15d8",
            "4fc2070c787449cf93b48e87603a90fe",
            "4ef154945ee8433eaea3f5fc6a2f4ed9",
            "61dda255679141a99285058d120422f4",
            "9bb3454f272e409aa3558cc8f23c05b5",
            "ba13a7d70a8f4f049baae82d2165dd2f",
            "b3459cefb6a844acb53b0c64a476223b",
            "affd3f64005842e890858d6f684bc37b",
            "1446fc8272ec496ab7b6b9cd0181aa82",
            "a294390436994c55a903c8874bb4b31b",
            "f2c6252d453d41368ec755e341ee4417",
            "b16be872e1d64ddf88422639ee4cb037",
            "729be85297f94407975ab30b9d744f63",
            "f5e2b7c1eafc44c98ae1f7fa494996ed"
          ]
        },
        "id": "_lnywJkqyL64",
        "outputId": "fea1508b-ceff-48bf-b2f3-d5e729fe7465"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9649c74a9b9a437396984b2135aecd39",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fd6e2d9dfe6b4971b80364a499023d15",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a9e83b168f6c484c8e95e4b98e8a2142",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6474b8c5d4f54ed4977ae85e43c70e03",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "61dda255679141a99285058d120422f4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "model_name = 'distilbert-base-uncased'\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amArSfaYdTQ4"
      },
      "source": [
        "Η συνάρτηση που πραγματοποιεί το tokenization καλώντας τον tokenizer που επιλέξαμε. Το εφαρμόζουμε τόσο στο train, όσο και στο test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "de89104ddfd040c8bd67b64a0608ad81",
            "4a51e35d9de248009a4f0d6932b677b9",
            "0cffeb0607e74c22a35a9dc98a352241",
            "8f130456bb7f42bd9f39d36832afb1b3",
            "9b5fae10a0ec4bf59a95db510cd79b06",
            "3348c9d6ee004392a26d78a48d88e9a2",
            "1916674648c5488ab06da961ea451e58",
            "477f2e0c07cb4326a041d1aba230ca28",
            "22975604a4b64d019f1ae2a229cdc294",
            "2a7d41188efd4a8a8c6217c205d8a520",
            "012726410036450e96c2555c93e90f4e",
            "a14c5490998a44aaad12b0164d2d8d6d",
            "4656be63b1bc4f329c7d9cf2be3e7ba9",
            "3b35470618c74851b5993ed190b69000",
            "2fc984f8345a47a8bbd4971f9fbe5f4e",
            "576b2149ac914e54af35b1d2412b38e1",
            "3219ef677c554ded962386ce9fffec50",
            "264e50ad8edf4ba5babf5139c7c3b3f0",
            "626ca1f9355b4b6b8e9f14c087a7f4d6",
            "5889e2058108421e9ee73b31eb24751d",
            "0e215e8ec9714538b605652846c19bce",
            "76687a7aa8854505a8fa6a79036842ae"
          ]
        },
        "id": "-1AkZ0rLPq2d",
        "outputId": "ee37d940-fb41-4214-ee59-9df2a43f3fe0"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "de89104ddfd040c8bd67b64a0608ad81",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/300 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a14c5490998a44aaad12b0164d2d8d6d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/300 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
        "\n",
        "\n",
        "tokenized_train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
        "tokenized_test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "train_dataset = tokenized_train_dataset\n",
        "test_dataset = tokenized_test_dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9G6xI_ycdkGs"
      },
      "source": [
        "Τυπώνοντας το train ή το test set, βλέπουμε δύο επιπλέον πεδία 'input_ids' και 'attention_mask'. Βεβαιωθήκαμε ότι υπάρχουν, άρα και το tokenization έχει επιτευχθεί."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWFzP_7SQVOm",
        "outputId": "a3d68a84-434a-46d1-d71b-f0f299b9fe41"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
              "    num_rows: 300\n",
              "})"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qSKY-FbYg89g",
        "outputId": "03b68a21-7496-4e02-ce8b-1677766479ea"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
              "    num_rows: 300\n",
              "})"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIFmCKWS1Zj6"
      },
      "source": [
        "## Χρήση του PyTorch Trainer για fine-tuning\n",
        "\n",
        "Η κλάση [Trainer](https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.Trainer) έχει βελτιστοποιηθεί από τους δημιουργούς του Huggingface παρέχοντας πολλές διευκολύνσεις και λιγότερη 'χεράτη' δουλειά. Θα τη χρησιμοποιήσοθμε ως εναλλακτική του να γράψουμε το δικό μας training loop.\n",
        "Καθώς η Trainer δεν τεστάρει αυτόματα την επίδοση του εκάστοτε μοντέλου κατά την εκπαίδευση, παρέχουμε κατάλληλη συνάρτηση προκειμένου να αποτιμάται το accuracy του μοντέλου σε κάθε εποχή."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0MPHrmRL1Zj7"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import evaluate\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "from transformers import pipeline\n",
        "\n",
        "metric = evaluate.load(\"accuracy\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    return metric.compute(predictions=predictions, references=labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31RdBzz01Zj7"
      },
      "source": [
        "Η κλάση [TrainingArguments](https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.TrainingArguments) περιέχει όλες τις υπερπαραμέτρους με τις οποίες μπορούμε να πειραματιστούμε κατά τη διαδικασία fine-tuning.\n",
        "\n",
        "\n",
        "Καλούμαστε να πειραματιστούμε με διαφορετικές υπερπαραμέτρους όπως το learning rate, batch size κλπ, καθώς επίσης και να ορίσουμε optimizer και scheduler για το fine-tuning. Θα εκτελέσουμε fine-tuning για μικρό αριθμό εποχών (άλλωστε το μοντέλο είναι ήδη προεκπαιδευμένο).\n",
        "\n",
        "1. Δίνονται σε markdown ένα πινακάκι με διαφορετικές υπερπαραμέτρους που δοκιμάσαμε και το accuracy που πετύχαμε στην τελευταία εποχή.\n",
        "\n",
        "2. Βάσει των πειραματισμών, σχολιάζουμε και αναλύουμε πώς επηρεάζουν διαφορετικές υπερπαράμετροι όπως το learning rate και το batch size το fine-tuning του μοντέλου που επιλέξαμε."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ga0fADv91Zj7"
      },
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "args = TrainingArguments(\n",
        "    output_dir=\"test_trainer\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    per_device_train_batch_size=16)\n",
        "\n",
        "\n",
        "# optimizer\n",
        "args = args.set_optimizer('adamw_torch')\n",
        "# scheduler\n",
        "args = args.set_lr_scheduler()\n",
        "# learning rate and batch size\n",
        "args = args.set_training(learning_rate=1e-5, batch_size=8, num_epochs=3)\n",
        "args1 = args.set_training(learning_rate=1e-4, batch_size=8, num_epochs=3)\n",
        "args2 = args.set_training(learning_rate=1e-5, batch_size=16, num_epochs=3)\n",
        "args3 = args.set_training(learning_rate=1e-4, batch_size=16, num_epochs=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nHWYlDW21Zj8",
        "outputId": "0d64a409-8e6b-4b32-f359-ad313fb095fd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "model1 = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "trainer1 = Trainer(\n",
        "    model=model1,\n",
        "    args=args1,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "model2 = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "trainer2 = Trainer(\n",
        "    model=model2,\n",
        "    args=args2,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "model3 = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "trainer3 = Trainer(\n",
        "    model=model3,\n",
        "    args=args3,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1I4coXA1Zj8"
      },
      "source": [
        "Στη συνέχεια, ρυθμίζουμε (fine-tune) το μοντέλο σας καλώντας το [train()](https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.Trainer.train):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "id": "PvY7bzp01Zj8",
        "outputId": "97170437-91a8-42c6-8f8d-2ffa479c5623"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='57' max='57' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [57/57 01:05, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.572438</td>\n",
              "      <td>0.723333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.255562</td>\n",
              "      <td>0.893333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.344317</td>\n",
              "      <td>0.873333</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "trained_model=trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "id": "FK6WZkdU4mMb",
        "outputId": "07ec8ad9-edfe-430d-e446-b6a229452a16"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='57' max='57' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [57/57 00:59, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.444531</td>\n",
              "      <td>0.800000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.371533</td>\n",
              "      <td>0.856667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.283467</td>\n",
              "      <td>0.906667</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "trained_model=trainer1.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "id": "HetMwJsS4mK5",
        "outputId": "06d31586-41ff-437d-dde8-43e29d7b7c4a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='57' max='57' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [57/57 01:01, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.444531</td>\n",
              "      <td>0.800000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.371533</td>\n",
              "      <td>0.856667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.283467</td>\n",
              "      <td>0.906667</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "trained_model=trainer2.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "id": "LpnNtbEtGoHD",
        "outputId": "b1772d1f-9a15-40e3-f8ee-0ec5e0152080"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='57' max='57' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [57/57 01:03, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.372972</td>\n",
              "      <td>0.863333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.283571</td>\n",
              "      <td>0.886667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.352167</td>\n",
              "      <td>0.873333</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "trained_model=trainer3.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-WbFB0B498Ck"
      },
      "source": [
        "α. Οι υπερπαράμετροι που χρησιμοποιήσαμε σε κάθε πείραμα και το accuracy που σημείωσε το καθένα στη τελευταία εποχή:\n",
        "\n",
        "| Arguments | Learning Rate | Batch Size | Accuracy |\n",
        "|-----------|---------------|------------|----------|\n",
        "| args      | 1e-5          | 8          | 87.33%   |\n",
        "| args1     | 1e-4          | 8          | 90.67%   |\n",
        "| args2     | 1e-5          | 16         | 90.67%   |\n",
        "| args3     | 1e-4          | 16         | 87.33%   |\n",
        "\n",
        "β. Τα πειραματικά αποτελέσματα δείχνουν ότι τόσο ο συνδυασμός μικρού batch size με μεγαλύτερο learning rate (8, 1e-4), όσο και ο συνδυασμός μεγαλύτερου batch size με μικρότερο learning rate (16, 1e-5) οδηγούν σε καλύτερη απόδοση, επιτυγχάνοντας 90.67% accuracy. Αντίθετα, όταν χρησιμοποιούνται είτε και τα δύο μικρά είτε και τα δύο μεγάλα, η ακρίβεια μειώνεται (~87.33%). Αυτό υποδεικνύει ότι πρέπει να υπάρχει ισορροπία μεταξύ learning rate και batch size, προκειμένου να ενισχυθεί η αποτελεσματικότητα της εκπαίδευσης."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0eR7gCPovmFN"
      },
      "source": [
        "# Μέρος Β: Χρήση fine-tuned μοντέλων σε νέα tasks\n",
        "\n",
        "Στο κομμάτι αυτό της εργασίας δε θα πραγματοποιήσουμε εκπαίδευση σε γλωσσικά μοντέλα. Αντιθέτως, θα εκμεταλλευτούμε τις δυνατότητες του transfer learning για να αντιμετωπίσουμε πιο πολύπλοκα γλωσσικά task, ανάγοντάς τα σε κλασικά task όπως είναι το text classification, natural language inference, question answering και άλλα.\n",
        "\n",
        "Για παράδειγμα, fine-tuned μοντέλα για [text classification](https://huggingface.co/tasks/text-classification) εξυπηρετούν tasks όπως:\n",
        "\n",
        "- Είναι δύο προτάσεις η μία παράφραση της άλλης? [Paraphrase/No Paraphrase]\n",
        "- Συνεπάγεται η πρόταση Χ την πρόταση Υ? [Entail/Neutral/Contradict]\n",
        "- Είναι η δοθείσα πρόταση γραμματικά ορθή? [Acceptable/Unacceptable]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vy3VluE4i3e6"
      },
      "source": [
        "## B1. Piqa dataset\n",
        "\n",
        "Το [Piqa dataset](https://huggingface.co/datasets/piqa) περιλαμβάνει προτάσεις οι οποίες ελέγχουν το βαθμό στον οποίο τα language models έχουν κοινή λογική (commonsense). Συγκεκριμένα, αποτελείται από προτάσεις και πιθανά endings, τα οποία απαιτούν commonsense γνώση για να συμπληρωθούν.\n",
        "\n",
        "Για παράδειγμα, έχοντας την πρόταση \"When boiling butter, when it's ready, you can\" υπάρχουν δύο υποψήφια endings:\n",
        "- \"Pour it onto a plate\"\n",
        "- \"Pour it into a jar\"\n",
        "\n",
        "Ένας άνθρωπος μπορεί να συμπεράνει ότι η δεύτερη πρόταση αποτελεί ένα πιο κατάλληλο ending, αφού το λιωμένο βούτυρο είναι υγρό, άρα το βάζο είναι ένα καταλληλότερο δοχείο σε σχέση με το πιάτο.\n",
        "\n",
        "Για λόγους επιτάχυνσης επιλέγουμε ένα τυχαίο υποσύνολο 100 δειγμάτων από το Piqa."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504,
          "referenced_widgets": [
            "ee433d3e2a5b4e488abb4fccba619175",
            "fb372d710ce849b8b353823feb898edd",
            "6f6ebbd8be374067b9bc39e12094cddd",
            "f3299cbcbc744ef186b999a1def10e0b",
            "6103ad411c9f48f78bd9ad78c3698429",
            "d2496365ca914cc9a0755fee24234114",
            "8929ff5326d04a6a9098c119448e0574",
            "c92608c61dc6422587e1547c0215161a",
            "e30c1ab6d5a7406dbf122aeb0c07cdb5",
            "10f76dc16322483e9009262f40e7aadf",
            "1c809dbb191a4353b7b76170650f447d",
            "531b32d7cd2945c29e50ffab6ee137f8",
            "2e3af2ae4f7a456baa700339eebd2b06",
            "dd99ed13772748ee923385110c26eca3",
            "83040aae226c44a69a94d2376c885b9f",
            "f1e66652f14e4607ae5bfa26047afcb1",
            "8ba364af30f547dca19c1d1b466e0605",
            "35269e4ddbb049f0883abd2b3f79fa21",
            "0550a63f18dc45039347d28fa43b137d",
            "33a2c14e8a944e7b8fbf4efeaf2aab31",
            "2c762786612d41b494ac9f16ecd2ebe8",
            "2f6ec9ca0ea145c4bcfc4560b75df7e4",
            "2e9656af979840da89ed5bf241f8bf16",
            "6d80fa0de1314d088b6d77c8f3d758c1",
            "851ed0f5b31747069ebc73476ce9461c",
            "e6e590dc8cfb434bb50bd9cd24530726",
            "ced646d279d6411795a3550a0b1f018c",
            "3865deb3ddcd44b89b7c168ca64694f8",
            "5e11ec78919847ca867a8adfb5f27b0f",
            "29e3debf877f459f9359b584430f8eff",
            "5bed5eda837f4fb1b4bf8a542cbe30c2",
            "62a0b648c9f74b46b04cdcf362690b93",
            "8ece00b5eec340a0b21f5938471110db",
            "158d8563399d40cc8774e7851307ff94",
            "029d0384bb7346fca53b1c9cc0726ddd",
            "a0b3b62d483e48f394d9f6cfcb77ce66",
            "3709368bc9fd42b597fd9b9b99e05df2",
            "2d6790d1e76740eaa88800eefb82b1f2",
            "a75eb56b210041e6870acc4cc686762b",
            "34a67abb608b4b2a9c73069d4a416885",
            "b148f0fb1f2d4687a499205825ca0d75",
            "a87bd25c26114c35b47c4beae5739ad5",
            "641888b5f110457dbe3abc8205a9ba70",
            "a2023023a5924ed4b1f7b8ed383d844b",
            "5d5ee99405b24d30999a09159869a3e5",
            "1badf29087c644f8a853f89055c77b70",
            "e4c1466ed0e94d14aa59d5d783469262",
            "c2a7383fa12f45908fd841fcdb08d1b1",
            "fef42bed1a434fc9b52960ece36ebfb1",
            "aae8b930f1a549a5b0e44f95487bf3aa",
            "6b756f4e92b24952a7c4fb94de9ab7a0",
            "c757de657d5c49549aa9b47b36edf008",
            "915f0ecf78c4409fa6763dcaa418860c",
            "41eea4acd34142f6b5f8d9485ac41e2b",
            "439fc4e08dd142c5b8c20e9c0c8700ac",
            "c3c2dff932a04aa880a9fb2feb17c40d",
            "c6ff4975f810454697980a26e1e85694",
            "3a792ac37a754750aa3c545973837b4a",
            "b1b22f8e28e54045a664bc94aa6b5217",
            "f1069c432f8e47cab09fcc0f9a4699b6",
            "1c13246486ac42b7b8da4a31fed7a4b1",
            "9e507f69f179481d9e136fbcac3ee9dd",
            "0ca82f4c08dd43b38b75cfda7efc3679",
            "d4d90490bd2244c6a0b70dbe23ba817a",
            "0bfffeaa7263451d93d252c22cb4a3ff",
            "e8fd860faefa471ba2d56011e639b604",
            "6d3e544ce1bd4bb0b896413e920ed47f",
            "243d118a13334ea29bd1a3e7f3c41f07",
            "837e836dd2ff4585b25a99a4f1ae05cc",
            "8a034cbf302b445b9fefe91facc40679",
            "f535c9ae9d054eb496850c2c8e0a620e",
            "b9768ffb83264d2ab84eb14b6b340120",
            "3d696a1ddc8c4e11b80e025e9c0f378a",
            "438402c45c1745eaae44961cc27561c7",
            "a3e68d9884ca45c1a2624d981813daa3",
            "bc8cb528c4bd457690325710d5813c42",
            "18149b219c544e5dbad940f8820cd138"
          ]
        },
        "id": "v4eyhC27i8bH",
        "outputId": "b4dbf495-86bf-4dfa-88da-9eeea8356360"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ee433d3e2a5b4e488abb4fccba619175",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md:   0%|          | 0.00/8.41k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "531b32d7cd2945c29e50ffab6ee137f8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "piqa.py:   0%|          | 0.00/5.36k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The repository for piqa contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/piqa.\n",
            "You can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n",
            "\n",
            "Do you wish to run the custom code? [y/N] y\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2e9656af979840da89ed5bf241f8bf16",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data:   0%|          | 0.00/1.82M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "158d8563399d40cc8774e7851307ff94",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data:   0%|          | 0.00/815k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5d5ee99405b24d30999a09159869a3e5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/16113 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c3c2dff932a04aa880a9fb2feb17c40d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating test split:   0%|          | 0/3084 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6d3e544ce1bd4bb0b896413e920ed47f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating validation split:   0%|          | 0/1838 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['goal', 'sol1', 'sol2', 'label'],\n",
              "    num_rows: 100\n",
              "})"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# load dataset\n",
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"piqa\")\n",
        "\n",
        "val_ds = dataset[\"validation\"]\n",
        "val_ds = val_ds.select(range(100))\n",
        "\n",
        "val_ds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_r6bijyOY_8"
      },
      "source": [
        "Μπορούμε να θεωρήσουμε το παραπάνω σενάριο σαν ένα πρόβλημα πολλαπλής επιλογής, όπου υπάρχουν δύο πιθανές εναλλακτικές για το ending της πρότασης. Συνεπώς, αξιοποιώντας σχετικά μοντέλα μπορούμε να επιλύσουμε την επιλογή του ending δοθείσας της πρότασης.\n",
        "\n",
        "Θα καταγράψουμε λοιπόν το accuracy πρόβλεψης endings για κάθε πρόταση με χρήση γλωσσικών μοντέλων. Για λόγους σύγκρισης θα χρησιμοποιήσουμε τουλάχιστον 5 κατάλληλα μοντέλα."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p7hAOca7jkuw"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "logging.getLogger(\"transformers\").setLevel(logging.ERROR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a6lSPO6NMekO"
      },
      "outputs": [],
      "source": [
        "# models\n",
        "model_names = [\n",
        "    \"sileod/deberta-v3-base-tasksource-nli\",\n",
        "    \"facebook/bart-large-mnli\",\n",
        "    \"joeddav/xlm-roberta-large-xnli\",\n",
        "    \"MoritzLaurer/deberta-v3-large-zeroshot-v2.0\",\n",
        "    \"typeform/distilbert-base-uncased-mnli\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OG2CkRVCOHtE",
        "outputId": "a98fd399-8c43-49fc-a2f4-ad1ff60bb306"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of  sileod/deberta-v3-base-tasksource-nli is:  71.0 %.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of  facebook/bart-large-mnli is:  60.0 %.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at joeddav/xlm-roberta-large-xnli were not used when initializing XLMRobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Device set to use cuda:0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of  joeddav/xlm-roberta-large-xnli is:  49.0 %.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n",
            "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
            "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of  MoritzLaurer/deberta-v3-large-zeroshot-v2.0 is:  74.0 %.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
            "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
            "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
            "Device set to use cuda:0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of  typeform/distilbert-base-uncased-mnli is:  53.0 %.\n"
          ]
        }
      ],
      "source": [
        "# function for ending prediction\n",
        "from transformers import pipeline\n",
        "\n",
        "for name in model_names:\n",
        "  classifier = pipeline(\"zero-shot-classification\",model=name)\n",
        "\n",
        "  correct = 0\n",
        "  for idx in range(100):\n",
        "    text = val_ds['goal'][idx]\n",
        "    candidate_labels = [val_ds['sol1'][idx], val_ds['sol2'][idx]]\n",
        "\n",
        "    prediction = classifier(text, candidate_labels)\n",
        "\n",
        "    best_label = prediction['labels'][0]\n",
        "\n",
        "    if best_label == candidate_labels[0]:\n",
        "      result = 0\n",
        "    else: result = 1\n",
        "\n",
        "    if val_ds['label'][idx] == result:\n",
        "      correct += 1\n",
        "\n",
        "  accuracy = correct / 100\n",
        "  print(\"Accuracy of \", name, \"is: \", accuracy*100, \"%.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tz8-kVRS1w2q"
      },
      "source": [
        "## B2. Truthful QA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d59haHDaA3X0"
      },
      "source": [
        "### Sentence Transformers\n",
        "\n",
        "Οι **sentence transformers** χρησιμοποιούνται για να δημιουργήσουν **embeddings προτάσεων**, δηλαδή διανυσματικές αναπαραστάσεις των προτάσεων αυτών σε ένα διανυσματικό χώρο. Χάρη στον τρόπο που έχουν προεκπαιδευτεί, έχουν την ικανότητα να τοποθετούν νοηματικά όμοιες προτάσεις κοντά τη μία στην άλλη, ενώ απομακρύνουν νοηματικά μακρινές προτάσεις. Έτσι, χάρη στις αναπαραστάσεις που λαμβάνουμε από τα sentence embeddings μπορούμε να αξιολογήσουμε σε τι βαθμό δύο προτάσεις είναι κοντά ή μακριά νοηματικά.\n",
        "\n",
        "Η σύγκριση των διανυσματικών αναπαραστάσεων μπορεί να γίνει κλασικά μέσω μεθόδων όπως το consine similarity, με μεγαλύτερες τιμές μεταξύ διανυσμάτων να σηματοδοτούν πιο όμοια διανύσματα, άρα και πιο όμοιες προτάσεις. Δίνουμε για το λόγο αυτό μια συνάρτηση υπολογισμού του cosine similarity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rdaiwnFx_ipu"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "def get_cosine_similarity(feature_vec_1, feature_vec_2):\n",
        "    return cosine_similarity(feature_vec_1.reshape(1, -1), feature_vec_2.reshape(1, -1))[0][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKMb7XFcB0Hr"
      },
      "source": [
        "Για παράδειγμα, εκτελώντας το ακόλουθο κελί, δίνεται μια τιμή ομοιότητας στο διάστημα [0, 1] για δύο προτάσεις (\"This is an example sentence\", \"Each sentence is converted\"). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545,
          "referenced_widgets": [
            "5e723eff17b94b169a4e334773640118",
            "69d1b6dada0b4ca0b7e33858917ec68b",
            "65a2419e4f984de59ce0e3ccb209f2fc",
            "787f4f7d46644fef85eab547b2ea90cb",
            "dd9987303e89418baf9bafdbbc65804c",
            "74fb15d9f4b346c998467b0692954e87",
            "5d7427c17ddc4d039eb68a9211bae76d",
            "454fdd2d972f4b4dab505aa7512d2109",
            "ad96778f6813404c981127988ee0639e",
            "6cdadff1ce1640199362830bb41fc3d8",
            "487bc9a80923480e867f0865a8ba60a1",
            "07ee8230def7420c8f461f4ab866fa06",
            "71d822585f6b424393e7cae4a690481a",
            "119309b89b504a01a56e2c40ae4179a3",
            "c1028352d00d42d88197e644d9defb84",
            "5c6f4dbc15544291ba92fa2fa53a5e8f",
            "9d2402d6691247b69fba48f52ce0ff74",
            "21e513d69ba34239b80dd45c77910fb0",
            "e91a3081b75646f7ad0f64b0c7d925f9",
            "95300d8d801e4cabaaaafc2e0c47ba28",
            "d0eb5ff014ba481cb41a9918148f52e7",
            "d8dce42cbf2c448bb25d314bd395854d",
            "c8d126ccfeea4542aa39c24076d13f1e",
            "3e573789c95b4c82815cde8f256fb8b5",
            "0dc3756e34174552b5bf5d28dd4ee540",
            "5f7f6c0d78f441989b89fa61b062f9e4",
            "4eed3a9fccf34941a976b8e5bbb3e0e0",
            "fb6a05dfcad84e3aba99021548f386df",
            "25eef59d3aec432badf095de54eaf4e1",
            "b6b53c6ce7194afebcf0bd524d936517",
            "fbbd661f20e94fff8eee7effb46edaf0",
            "f633d929d1234dd2a662ac1b8aa8c540",
            "45a0c73cde1d4b76a8dfd225765d5a0f",
            "b1cfadfd5ef94626a79bd3189f835834",
            "ede6ae1e9bad4700ad21feb8b9fbf63e",
            "60f9194bcb8044949bbc70f68c39c3f4",
            "1d14a8c3489e448a88cdfa38c1fbf656",
            "a4e7e9e80d324a059e042e5ed8213ac8",
            "5ee85e7082e34bc3a781da904ca3ab5e",
            "9bb5615ab08c4a74a0f117e5449823a3",
            "aa4d330cf7024337a3f668e9b389ed50",
            "b298911fff654df68e57103077dfe8be",
            "d81f1d753bcd40a6a4b457f2f33369ee",
            "d402274d294a499589adfe191d21a2e4",
            "d50ebf28cf614a7d9bac2e46cd50cab1",
            "f12efdf979634a92bac3e10335f743e7",
            "c1c4b74edbd14fc084f1977e89adf016",
            "e57772b3d9194df3963fe50a0627cc9d",
            "887e8d91460a459fb27ffef383785baa",
            "d34f6fa0eb1a4da38143aaea0010a05c",
            "38dcd85fe3664b8a9fef524a6f157538",
            "fb8ac911c6274554802df6bfed332e70",
            "bd2429b5bf0b45d897b21e13101c04bb",
            "bdb35da7daa04ea489d6538322e6e161",
            "f7d7ca259deb4c01a173c4cf148d8425",
            "3a4a9298feab4665a6324cef2ffac80e",
            "1a5d51c31cf1484c81fb07b85460939a",
            "1c8e54d6951349c48fb6e2c02eb4d2dc",
            "8844c244044e48a79e98ccd7f22f33bb",
            "f201e648ec2748f18dcea916c4e9a17b",
            "a3ddcfbadb0a446590fa512ea77bb666",
            "488f94a3c0b84e56875b3bee8c95471f",
            "fb20b3b719a441a39a3c92b458fc5572",
            "06c9f8bb2a284ec48e5eee4de823d13c",
            "ea2bfc9e0ff24621b5d9d51f18d0bf11",
            "2d1f21009ed64765b1ff9b4e85283497",
            "102b792b6d484121b2b306712713f518",
            "990ba0f99c694a4f8041549b9f991e01",
            "489d45e481fc466e97e101cc6b6fa7fd",
            "029f057829734324b008edb5055c2194",
            "cbac376c3bd549879001733fcd5a75aa",
            "3e8d28af5e8d4395b082a52ea0a74d1e",
            "9acc7c38cc21411580a916d45a1855ab",
            "851b036c958a4afbbae2d4a0d4c22fee",
            "15b6797e07a24e3592bd2c91a9b72bc6",
            "b0d5ba4b398e4ace976ae189fd7e7e11",
            "1e44eb5be2844ed3924f9a4221b9f076",
            "c710a0a131cb46bca4b580f1f9d2a214",
            "cd076a607af943a79e6cfa8817b57b94",
            "a11c7a12e7934b1eb98342b7c4dc9601",
            "1f15f2b4773042dfb025ede0c33a66a4",
            "e2768c7ee8564934afd980201a3a1a2d",
            "532201d9901e4342a86ae6288faba02c",
            "cbeea957ba014722bf963b3ed31a4eeb",
            "ebc77d7214fd4875932133de423ce410",
            "72143a22bed248ffb6763345a84aca25",
            "0dc15225ac3b4c0abfbe090bf6cf13ee",
            "83f15c535b35492f867918926ca25028",
            "ce9670336bc24210b7b5481ac43d7b8f",
            "4ea855e6c6674166a6600ac926dab748",
            "227e3e33843e47f8abd76ef994746857",
            "9e691f068799467aba1e249501580341",
            "9784788f51c14031a887a2629710eb90",
            "0d4e929e56744754bf198dcfe838ab69",
            "18130103911741e49be209fb098522b2",
            "449396a4deb3449f9ae2323c25eaa7b7",
            "97858cb174e148f7bee10550bb5f518b",
            "cfd902a4ed8d4f81b1d8b2c5ef2dcef6",
            "18baf824277749099ffe4634bc4f38b4",
            "85b995746e3243c091d43edbcb795034",
            "c236d39fbde5482baaa015fee62da529",
            "b0c9e2a6f251439db23cadf4d3ce3480",
            "fe528d8c42a34727b29b750fb682d02b",
            "d34bb30d6caf4744b4dd4903e77b4c09",
            "710ae771fb114572963d9d9da2e39390",
            "86693ec825184e97aedb1e750224fd55",
            "9bd0871aa35f4de98a2b5b2436dd10eb",
            "1943e53e037a4dceb3f11385b31e233b",
            "8e04961a35e4415ea8d93247d26fea64",
            "7e6fc85abd7f47e7bbd4e1d4975d4d1f",
            "c2aac4286cc546588960c2580a1e5fdd",
            "ee0830da2f1c4709985ac45eea983b0e",
            "33e22128fa844ecdb0a95978438d74e0",
            "0e71f003a0cc4071a6d39dc9628737cd",
            "517c635b98e34c6e9516228bbc00239d",
            "6fce4abc6f7146ba9411b0110a0e98c7",
            "13854898678f406c979ddbd89a62eb3c",
            "51c47349e50c40e7b440e3d62cd2daa1",
            "1917dff7e72d43ea9f23922f5ff48631",
            "739075681f6f4f8dbb1a925199e8c976",
            "2ae19f0df98a4df5a9b3d71bc800dfd0"
          ]
        },
        "id": "UGhq0UGF-bW0",
        "outputId": "e45ddaac-8e5b-4676-f7c7-7d5355d48b6f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5e723eff17b94b169a4e334773640118",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "07ee8230def7420c8f461f4ab866fa06",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c8d126ccfeea4542aa39c24076d13f1e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md:   0%|          | 0.00/10.4k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b1cfadfd5ef94626a79bd3189f835834",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d50ebf28cf614a7d9bac2e46cd50cab1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3a4a9298feab4665a6324cef2ffac80e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "102b792b6d484121b2b306712713f518",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c710a0a131cb46bca4b580f1f9d2a214",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ce9670336bc24210b7b5481ac43d7b8f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "85b995746e3243c091d43edbcb795034",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c2aac4286cc546588960c2580a1e5fdd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "np.float32(0.40488452)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "sentences = [\"This is an example sentence\", \"Each sentence is converted\"]\n",
        "\n",
        "model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
        "embeddings = model.encode(sentences)\n",
        "\n",
        "get_cosine_similarity(embeddings[0], embeddings[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rzaa750mCZp5"
      },
      "source": [
        "Για τη συνέχεια της άσκησης, καλούμαστε να επιλέξουμε τουλάχιστον 6 διαφορετικά [μοντέλα για semantic similarity](https://huggingface.co/models?pipeline_tag=sentence-similarity&sort=downloads) από τους sentence transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8iGiDmwBCuKR"
      },
      "source": [
        "### Μπορούν τα question answering μοντέλα να διαχωρίσουν αληθείς και ψευδείς προτάσεις?\n",
        "\n",
        "Αυτό το ερώτημα θα το απαντήσουμε στο παρόν κομμάτι της άσκησης. Για το λόγο αυτό, φορτώνουμε το dataset [Truthful QA generation](https://huggingface.co/datasets/truthful_qa/viewer/generation/validation), το οποίο περιέχει τις εξής επιλογές:\n",
        "\n",
        "- best answer\n",
        "- correct answer\n",
        "- incorrect answer\n",
        "\n",
        "Πολλές φορές το best answer και το correct answer είναι ίδια ή έστω πολύ κοντινά νοηματικά. Σε αυτό το σημείο είναι που θα αξιοποιήσουμε το semantic similarity για να αξιολογήσουμε την ομοιότητα αυτή.\n",
        "\n",
        "Φιλτράρουμε το dataset ώστε να περιέχονται 100 δείγματα συνολικά για λόγους επιτάχυνσης, εκ των οποίων καθένα θα πρέπει να περιέχει τουλάχιστον 2 correct answer. Θεωρούμε έτσι 4 υποψήφιες επιλογές:\n",
        "\n",
        "1η επιλογή: best answer  \n",
        "2η επιλογή: 1ο correct answer  \n",
        "3η επιλογή: 2ο correct answer  \n",
        "4η επιλογή: incorrect answer  \n",
        "\n",
        "Οι επιλογές αυτές μαζί με την ερώτηση δίνονται σε ένα μοντέλο πολλαπλής επιλογής σαν αυτά που χρησιμοποιήθηκαν στο ερώτημα Β1. Μπορούμε να θεωρήσουμε τα ίδια μοντέλα και να τα επεκτείνουμε σε 4 υποψήφιες απαντήσεις.  \n",
        "\n",
        "Το semantic similarity θα επηρεάσει το τι θεωρούμε βέλτιστα σωστή απάντηση, άρα και το accuracy. Συγκεκριμένα, θα λάβουμε διανυσματικές αναπαραστάσεις για το best answer και τα 2 correct answer που έχουν δοθεί ως υποψήφιες επιλογές μέσω κάποιου semantic similarity μοντέλου. Σε περίπτωση λοιπόν που το μοντέλο πολλαπλής επιλογής προβλέψει ένα εκ των correct answer, και η ομοιότητά τους σε σχέση με το best model ξεπερνάει ένα προεπιλεγμένο κατώφλι ομοιότητας, η απάντηση θεωρείται βέλτιστα σωστή. Θέτουμε λοιπόν κατώφλι ομοιότητας το 0.95.\n",
        "\n",
        "Για παράδειγμα, έστω ότι το μοντέλο πολλαπλής επιλογής μεταξύ των υποψηφίων [best, 1st correct, 2nd correct, incorrect] επιλέγει το δεύτερο στοιχείο, δηλαδή το 1st correct, και δεδομένου ότι το cosine similarity μεταξύ των embeddings του best και του 1st correct είναι > 0.95, τότε θεωρούμε ότι η απάντηση είναι βέλτιστα σωστή, και συνυπολογίζεται θετικά στο accuracy.\n",
        "\n",
        "Θα γράψουμε λοιπόν μια συνάρτηση που να υπολογίζει το accuracy εύρεσης βέλτιστα σωστών απαντήσεων ανάμεσα στις υποψήφιες απαντήσεις, εξετάζοντας τουλάχιστον 6 semantic similarity μοντέλα καθώς επίσης και τα μοντέλα που επιλέξαμε στο ερώτημα Β1.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182,
          "referenced_widgets": [
            "126810c25fe046edb38791a5fc84b332",
            "a4b149e53a9648aebba295824c399326",
            "bec77855d35f4732b34153347d0a5d32",
            "98029e9219dd49078e7f309b4c5aed5f",
            "6ab95bb817d44118b88b323380ad3e49",
            "8e57ab2ce22d498d89cc4d009952aebc",
            "2cca7197da2e4f34bf8cbc402041e4f5",
            "6bd1365b6e7948d98f34127b0c07c911",
            "3d3a1f5ba8b94bbba34c70222f20227e",
            "5677d8476285404e875ec4d6bfc762a2",
            "1e3f00e2cd284d8fba21bab439c529f6",
            "a64832217494414f8c42952d892d9905",
            "45688f3dd3884323b866a5c78b6c3c5c",
            "d347bce47f694baa826e35aaa498aca5",
            "f4296037cffb4c7d8b1ac8371f4230ef",
            "6ebc0ad664b34cfba395ab49798c69f8",
            "aa69a15003844f9d856c4e0f90fb2d84",
            "7638483c5e4c465997f85593259d9dbc",
            "af7ba6bd4acd4f58b66c3438f1599709",
            "07c99ea6b4ec4c628b57f10e28dcc45f",
            "79994bae56c64329b120fa2252719f79",
            "6adb88a5e31e496eb320c997766e0a52",
            "41fc0558b6eb43e4bea0fe8ada016d2b",
            "42b55780e521495ca3ab6c4a62629a39",
            "66eb25922a7d4f8992187b9ec14ce7be",
            "3fc93439adec4227bff56dc286473691",
            "e838e11aa1d64b279b4b4817448bbed7",
            "b49c009381f74733a65e08723f5edeab",
            "c76e5ce56fbf4be2aa8720144fe06402",
            "7bf0cc37d8e643578c907ba9356ba2da",
            "60549d5666044a11a5987cd6d1d57f6c",
            "75511e1811684ffbae7847f52c6101b4",
            "5e85f8eb2c4044af8a37909e26822d7b"
          ]
        },
        "id": "B3aXIPmDIA7F",
        "outputId": "e089295e-d66a-4998-fa8c-284197a6d6f6"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "126810c25fe046edb38791a5fc84b332",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md:   0%|          | 0.00/9.59k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a64832217494414f8c42952d892d9905",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "validation-00000-of-00001.parquet:   0%|          | 0.00/223k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "41fc0558b6eb43e4bea0fe8ada016d2b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating validation split:   0%|          | 0/817 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['question', 'best', 'correct1', 'correct2', 'incorrect'],\n",
              "    num_rows: 100\n",
              "})"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# load dataset\n",
        "from datasets import load_dataset, Dataset\n",
        "\n",
        "dataset = load_dataset(\"truthful_qa\", \"generation\")\n",
        "ds = dataset[\"validation\"]\n",
        "\n",
        "similarity_ds = []\n",
        "for example in ds:\n",
        "     if len(example[\"correct_answers\"]) >= 2 and len(example[\"incorrect_answers\"]) >= 1:\n",
        "        similarity_ds.append({\n",
        "            \"question\": example[\"question\"],\n",
        "            \"best\": example[\"best_answer\"],\n",
        "            \"correct1\": example[\"correct_answers\"][0],\n",
        "            \"correct2\": example[\"correct_answers\"][1],\n",
        "            \"incorrect\": example[\"incorrect_answers\"][0]\n",
        "        })\n",
        "\n",
        "similarity_ds = similarity_ds[:100]\n",
        "similarity_ds = Dataset.from_list(similarity_ds)\n",
        "similarity_ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IZSQmLMDIJ3A"
      },
      "outputs": [],
      "source": [
        "# load models for semantic similarity and QA\n",
        "similarity_models = [\n",
        "    'sentence-transformers/all-MiniLM-L6-v2',\n",
        "    'sentence-transformers/all-mpnet-base-v2',\n",
        "    'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2',\n",
        "    'sentence-transformers/use-cmlm-multilingual',\n",
        "    'sentence-transformers/paraphrase-MiniLM-L6-v2',\n",
        "    'sentence-transformers/paraphrase-multilingual-mpnet-base-v2'\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "855194fc97a84cc392c88546a55e19e4",
            "ad51bbc1a7f149daa0356f39a16960ad",
            "6f7de7e16c1e4c68a7d716e8e522b207",
            "5a8f6cdd2460465bb8885c6a8adf4e78",
            "ed9452a2107944acbc050cdc9b60af7d",
            "014c3ba569ea49ec9f82d095321f2eb0",
            "61d9b93777b84a9da0eef32b598b65a3",
            "c9ed59448a37443d9795f8228e14ac55",
            "8bc46e5a603a4b5581ab5e3c2c66501b",
            "fa264c76ed6144df8eb11a6453541bc2",
            "4394e562c28645c5b889f7bf4c8602b8",
            "764ae471c3de46cca1e2977e74380f01",
            "89239026a97649f487700b5f48443f65",
            "69a4d69f13a04788b58e1ba6d2656ef6",
            "37b1d0c3be4e4fe2a010bf40f78cf6ce",
            "40a474690ad64e65900c3d4701ad8b2c",
            "b5c4b019a2ef444a9a8e2b9eeb77f278",
            "18dac3fe12884b378866abf4b2340c85",
            "72a45d31571348848a7b2d4e499bcb37",
            "f222272951144468b1850149736d2a3c",
            "7e5a5041b25b4629b6eb1c41a2996a90",
            "92b4c262e3454ee6b015be8112541470",
            "5c74ece81504446999fd8aca7fee3bbc",
            "6420f915787245f89369d508628a2e41",
            "97c409db36d5494bb58a91e471d61573",
            "395adeb814a5439686238864800981a6",
            "4b9783e3ab414c12925efeca72490feb",
            "d8d0ed89926a42fa9dd80303a4e42ce9",
            "fc174824f5654d268175b802a9fe6a99",
            "aebdfb02651b46d9a809ba2fff9ddc6c",
            "e6ca4e3db4e9495ea94be5591471cfee",
            "834d72bf220c49e6a2bb9f7153a77a82",
            "b637c64283da457d9c06c802baf78ea1",
            "d7db9d48d9f14b28af4cba0ce970ab40",
            "5f62f30525bd4630a51fe12678e39bdc",
            "d12d79e29dd34ec4b9863458889ac4ff",
            "37e549b758464011923f53bcd6e6d401",
            "a2c76d38f2dd4b7bad5325b5270b8e4e",
            "df3b3112ca044aa0a68a4c2f761cc965",
            "1784f99e008e4db887efc36e4351f470",
            "cb7e1733332649a18f7cc4fcdcde4b8c",
            "ac5e987d4ed24759b5c43d96c5a6508a",
            "9fb458cfcf824798ac23f11f54922310",
            "9e95982b573c45b8a09111e4bbd4b6f4",
            "d8f7208d4b1346cbb7dac183cabb2d21",
            "898342b70b8f4d91967fcc0b1ad99ac9",
            "61d7f6c9e89c45c99927f467690a96c9",
            "c41d21ca4af54b55bb652a2e69a79797",
            "633ac57313c8434cae2c35de8d910dbb",
            "ac44bf6c170e49459401895a91dfd470",
            "14e586862a7a47a48d37944b9f1bd5a5",
            "9e6308842ce84bd8b46c3fed2bcda283",
            "86a850330e4344a88b1d59dc0802a604",
            "671e8b2733ff4b6d83c4a3a05181f01b",
            "c735af0480a6462582f1d3de900a6231",
            "8aeab9c12da94501bf0c8d9b636344ab",
            "20eb2ea9d5404133813b7b91488a0f66",
            "b63a68d89435487d9ff9dbe54fa9951c",
            "3bd9382ee1cb4f2fb20cafc82ccbd0df",
            "6409bbed9f9343509c387550aa3c3804",
            "3055936f776c4253a02bacb900be3677",
            "377b4269abef4b2eb9719aff59785f67",
            "ab3f3d9949444395a453ea86d354f0bb",
            "6d7e92ef95e14864a40aa123c3ac9921",
            "1497af7323514022aeda44c4fc39acc1",
            "1e1a608b840a4a4aba9d307e4f20002c",
            "ee6c461f3b8441d39a61f0eb3e56243f",
            "ef903b51093a442aafe132ed6ba22876",
            "8ae716d564d94232a0f6e0aeabe621c9",
            "f6a315de4655419a9cf8213a6c883e21",
            "0997aeab98494598af94bfa64d92df31",
            "8e2035cf0c6c46e69d2e7b239585b6e7",
            "6892772e5c434f598ef7bf1e2b327439",
            "1860134e1f374b9fb97ab520bc2de1d0",
            "cc7050723b364757b01693e504678978",
            "d454362930044692ad967cf6c2590710",
            "650bbe4aab4a48af82275ec62bee0cbb",
            "7747fc309bcb4d9483c0380e81e30335",
            "3f97860402c94992a104c6b6cd1a271c",
            "81f8ff35c67f4b028a2524351ce4e8b1",
            "0246c3c3eda845ffb533b5f378cd06e6",
            "25a9aacdf6af4942901e85804eb6a82f",
            "7f16b0fd68864260badc058665778d5b",
            "f28831235c094575952c6eaaa477ee31",
            "95a4ac9355044088957f75e55a8d60df",
            "b64a6a76f31d4f80bffce4f0ce177436",
            "e6a97a58bee041798d641968f0b028aa",
            "8ef3c5250c604b55ab66ffba6e588c2f",
            "c0b128458d2f47589f7d665151d999e7",
            "6d9a5311ab794f8cbc5093d28baa88b2",
            "57d29e842321414ca8fdf2f6de56b96f",
            "e5566027f712471eba8f4e58933b30b1",
            "db8f6c66647740819acc3f2d8ca8ddd3",
            "afa1c9166623487db966018912087071",
            "c731393771f94c61aec01d390acd75aa",
            "a891bd3ec7514e638ac8ae0e6aed1ef9",
            "ecc14dd1214d475ea91071bf3cf94c2e",
            "600036b38db1403ab9a81aaca6b23ee6",
            "e55ec2a4c1174b0dba1dd723f6e3a40f",
            "d5951c9014d74fe4a32b2d45e543d552",
            "c0caa7e3afcc4933852bc44f5a7556de",
            "5bf530485bd04a52a2d1a4c6192f412d",
            "88505f3285984e00b483ac71b795ff13",
            "10f24469023c4a06be0e6561ae26152a",
            "a1d5279ed139452f8796fcb3153b5eac",
            "d2588de19c044ca68597803c4315bbca",
            "dc895b0f5b2c481880574c04eafde186",
            "5db85e86347343ff9d662ab7adebafcc",
            "940105d724be495cb4e078e016d28a1e",
            "9bea94c07ae942bcb2e6f605687298d4",
            "720a006a788f4f2dabb7e82a72ed4012",
            "7372e353575846ff8b594f9fdb323e6a",
            "075f316a17874d7b8bb4b89a58c1e550",
            "1789a460c274457495d2d8fb8d419a7a",
            "e650dd7d65c44bbfbf871f56cc40e0b6",
            "405aac110a5041b5bf86c4bf39cb7621",
            "2d629ac771f040c0afb3f19a9deea949",
            "10e469d223e8416796d64532990026f2",
            "87d3d58e57934644b88b7b91f00a3e8f",
            "9d99cbe9762149dd91074094ba482247",
            "fd2de1a2857d428fa549ff4c1ce798e4",
            "fb76d7fbf1294b2cb3af7b0fc93a6001",
            "0fd53d1fd6cc48e8b63dd26c2509c045",
            "f21f145c64c445e4b9a9ef9f8924877c",
            "37ef9ab730a840798cd364c0ca7ac626",
            "1a13f956c2ed47cda8b820e594ec4341",
            "2f532cadbc4a4336abeecc1f657f47fb",
            "8ad96b95b8544a62b3e9cba41f494014",
            "36f35f9ed96842f7bd52bf44d89876a1",
            "ffdb23b6c5c44abab7bb0e193f922b65",
            "a8ea60e2b2074bd3ad57e0f2a0862f33",
            "3a3d9f1e3cd84788b6aadeb0617a52e5",
            "e4c3ddcf6c8f4533a08c9ac37af38644",
            "9d815004f9894096b2f60d1e0cc54f74",
            "61f39e4559a748618470e2aa67ecaf48",
            "a39d6e5a4ddf4a908e8d6ba35ac6a7bc",
            "9f64b57a7883419d9b12b5a23315609f",
            "b2c9234723604d12821e2eb3af9b14f4",
            "684d38ba1b184b5fa0a7de8111249037",
            "032de5227f2d4e21a4cc86d444026760",
            "cd5f04f5da5d4db7a476331216c25fda",
            "b239055bc4c94721950944e0b0be8868",
            "9f3da6bcf2034f64a94e25727b599ba2",
            "df578dca31d84e18995960fbbd65bf0b",
            "bc992c8995394d1681801fe81cc121ac",
            "f98d758742454a499a1d42dcf1ad222b",
            "2333efdb15394165805a91c148187396",
            "5b6860e22b40400f8e85f67c147a246d",
            "14d769c1ebff4e8d860fb0faacf193e4",
            "17c8529ada844a49a4ff3581cdfae652",
            "242356804068403ab8022ff2a7d2a63e",
            "26f20347ebec4f35bfcffb712dae1d57",
            "303869e75cac4465a2c119baeeef4f5e",
            "a7e99b206a304283aa653f796bc60b01",
            "6cd99799c9944315934c13e96ae59e97",
            "cab3a30da3b04e45b946235407eb2ed4",
            "b526193970ef42c7a23cb141cbdd4700",
            "dafc1ac6fd9e445b97479afb120e63a4",
            "5d67e2201d2746e5a5815b9249c931ec",
            "c3bb9483b88144a28a6e6a2000db123e",
            "d6476e07878b483bafe4254614d14ab1",
            "309d17007c964e558d545fbc7da70676",
            "7bc4aa2adb8b4d5296be5e9ebeaaa669",
            "feba8f556a8f4216a7d3866f09058ddb",
            "051ade5340ca42e086ae3d029df81e17",
            "9e65ae1dd826457f9255e7339c896a8d",
            "a5c624ab74e94073b6f24afbfd0b7db8",
            "bf13fc84c45849b69b008e26824014fc",
            "8f1ce780fa0843348189ed3ee00dba37",
            "e5b0ae8c91eb437c9420cbc40acdb788",
            "b3342ced97f343e4ae0ff408ffa18d14",
            "db9a32307a5045c782e36cc652a4c2fb",
            "42e4cb43957f4cad98e77e3913a091e8",
            "6d1866da65c347e4b7c51b3ffa389f53",
            "cfda185b3ae5492fbe20798e1fcb3c77",
            "07631bf7420b4026bb0194d4444bb0e7",
            "0f1f4a13e9ec49c4b367fb09c6d55eee",
            "3544732198cb4683871a253d7a8ccbae",
            "f858bd5e23fd4be8868fc3aeac9fcda4",
            "4fe57e4dc9e8494f93d60732fe8e7481",
            "2fbbee97952d448984ca6b6b828c21a7",
            "b3ea055128824047a4729c98a3972433",
            "664b09c67fd64f84a4d15f12275c8c75",
            "2b1c55e4a92f4fb095059bd93de517b2",
            "3a0ba4d306214d1d98fd07a7366b7106",
            "5ec359e4fad54be58787fe5e3b895ba0",
            "183cf1f95b1b40e4a538d7a1569af12d",
            "82e8d098981f4443952c32586a08106d",
            "d719130fbfa44bed97ce10707bba848d",
            "f35bc4455c27405682e62310f3f93697",
            "20c5c926050b4065814bea523f5497a7",
            "e44cbcbb6e5b4ae1b0687aeff27181ad",
            "e9179fe18c244115a95f0346413ab395",
            "ca482c65dc394575b390e295a3727c5a",
            "c775cbc1525b48edbc7193816e6d08b4",
            "f8463fafbf004a7090d3098a470e1867",
            "4e812e2fcb1043b68b83049e8306d78b",
            "0328887a504543d5b2240aae7cc03949",
            "65174ecb09db43c9bc8fa83e216d8742",
            "9b05018a409b404cb2b8d5c0050883df",
            "bf0114ee606b4c25863965051fb34846",
            "506e8ee6640b4dfe918f6aac0fd838e8",
            "5e78e710a94243cebcadf14942c3f69e",
            "8aee3072889a4674bb4570a9400fcc15",
            "e02185d9b34b4c3daf4e1603cb303cc9",
            "e2e291417f2e48139b0ab9a85db473de",
            "c8e8fff5d5b245ec80ed82f32489acbb",
            "e6da48c68c154d878ac7b28fb0d585e9",
            "dd7814db39fa412b92760056c242edd4",
            "8be4f3b86bd74c4d9a28b908505c0899",
            "961ad2391c5b4bf195b61e0539e28180",
            "b888d2ff79bf42e99e5de9e15b9ee574",
            "c8534f8e01e84164b3ff0e86007418be",
            "e3cf15f7549f43f5a5b9e2de305abbc5",
            "86f71ec3841c4d1fb158fe61a78596c0",
            "a8abb01029814286a9268b1c941d773d",
            "0ac43fbe0b19464685915b348b58349d",
            "623670df564e49b98cd99ae2ddfd0863",
            "6ade108a12b641728493bf37d8a803e2",
            "b3de49ffa71141b19c68308888870abb",
            "dd999ea186064edaab9940a18d40abf6",
            "5c4761afbcc84391bae9d11303810c16",
            "b38e1a2221994ca7aff7e9c41c3e4c35",
            "5374d1586769418e9b984be623456767",
            "f66abb50fa5b48cd84db3516793a0d3a",
            "af9e2e02acab4436a875b631547bd79c",
            "0e0763a95cce472b8fe30f7a63904dfe",
            "344155a0a55947e6815f0e0f3146f6b9",
            "1c8950f02b56425289fb5c9afba510ea",
            "81289a52c9a44311ab9fedb57aede91d",
            "1b68201cfd9546e4bfe61de441336d8f",
            "afbd70e6d5e44843bdcd043d9e3341fc",
            "221af60ae7e04152a957d830f7741863",
            "13b5d350d1944fedbd4d06491d10231f",
            "75aee2f3650e4facbf927f66076ccffe",
            "bd072f2aacda4b7d9d68ed103dfec225",
            "4431ec3d63c8466b82db404c150d5b78",
            "63a42fe255ef4d2ba09a318f67841bf7",
            "dd4cf5723dad4ce7a379564f241f3230",
            "057a107bf8d240008d292ea47702b29c",
            "18699b9b1f2f4520b6260667abbe911a",
            "c63ae51bbc8d467097b0f2c39977f0f1",
            "c1ec8ceafae14c3891594e447d22c432",
            "2a938ef6ec7a4622a6c6e5c5dd10c5f2",
            "591a7dfc12ce4aceb1439d924269ca23",
            "85c98759c80e48c2a9c732b0e2ee4b57",
            "bb186361bc634077bb2b00df9a022cb2",
            "133bf0bb41504987842063a21b231cd5",
            "19cfba3f70874998a5291edd2d0f2900",
            "f75469325e7c44bf81ebb843340d4e8a",
            "4c528133985c4dd48978647d1ac4d641",
            "ce09b7a7321f4d4e818b53a0527eeaa5",
            "f951106156bf4f2a93ba7081b946adcf",
            "3fb2b4309beb45ef9f7ef9f3a2c00847",
            "8fcd5dc980bb441c8999bf818ff56813",
            "8f3f7d0d978d46c8b1832adc079059cc",
            "2e252ac411d94497a2c7c329f5436b5c",
            "23f3a8d7b031436589aa9fe916b72104",
            "352b9b85768344879334813e03e77b2f",
            "7d45ffdd19684bdd826e9afaf6342133",
            "8928b11e86e54ab69a03df9898ad85d6",
            "3fbea470da6843c7821feed29999b75a",
            "dd08ae29d9ab478f8569c588bf131bb9",
            "5c73ae8a57fe400a8a0e79234d20a928",
            "f0910d21c6834fe3a39080e44dc58aff",
            "26765839bb1c4e6cb4996e4ab73524b4",
            "d41ef8dcc37c486696a880ccb75618db",
            "d3149c5f58b844beb4fc0a4f5b1bfea5",
            "5825dc1f433e4127b6e75e74f9c6d881",
            "2572e318996342a29120da371cb17377",
            "eccbed47afc341e6bc58efdefc485906",
            "5d58fad3aec24c53b46f328fb4b3251d",
            "37992bdd673e4f93885ea179ea0ad360",
            "5f1436c668874251a305e96de3b9f21f",
            "7683aec67c144bbdbdf12ed772961b87",
            "c553162f9ff1406f973ffc69d9fb17c7",
            "bef97e5e8f8a486fa217f283309d79a6",
            "f21c29f1ea1e4555bd186835841e0b4b",
            "60157e833c084abcbd6857018209ce07",
            "6f2bba7a65fe47abba1f274cbab16569",
            "e99068db69d444e8b45d8cbbe06bfb27",
            "a07aa35cb3bf47b187b1c764f0d5d0cd",
            "aa4e116112e64223a47478d6ade2808e",
            "f280d3836a114bebba1e353531d8c2cf",
            "cca4f11101d0466ea1a7a2fc044d04f5",
            "d083ccc51c6b43b89d056b0eb3e3bcb3",
            "1291ad86f4234b76b2298f31d31a8939",
            "a5e6e46903a546cc9034f5fb89486db7",
            "0e405093ef3644e2a9a366d70ba66238",
            "cd10e39000aa437094f062c0ea875bec",
            "9455126aa6e34f97907d15b997bfc4b8",
            "747205fa18da429e95c5bb0bb3dd2712",
            "313e0aecd9f64d7fbde9253b67a35c79",
            "4c8e5537d179430d8fb227fb10bf6341",
            "ed518eca7e9347a18e00d799b3ef627d",
            "dd97b5b62251445f938566c767bc4043",
            "f16f10e6e877412c8928b8ddf153b58a",
            "5ab0b6b49a9b4f7f94709f05d36d1573",
            "e758f7e8d2254862858e2cdeacbb280c",
            "e97027cdde8c49b1a6871d094fbbcf35",
            "ab8eadb1226e474c88cb0f5568e67ad8",
            "5b8db84416d44ace98fbe8642f002707",
            "abe9f4b556574bb48fb88e5405ac5dab",
            "0b935513d61544dfbc8c48d67a12e7e5",
            "46d8fb55d3e1479687e9aaf29d0d9730",
            "2eefbb7e007c40919a583b734c298453",
            "dfee8121c0ef4fc1ae2cded33100cfc7",
            "fb1aaf5882cc4fa789f6af1f33a81a59"
          ]
        },
        "id": "WCNrR5nV18_G",
        "outputId": "98e389ef-dd4c-4dc7-d8fb-2e4238cf4c61"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "855194fc97a84cc392c88546a55e19e4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/1.15k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "764ae471c3de46cca1e2977e74380f01",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5c74ece81504446999fd8aca7fee3bbc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d7db9d48d9f14b28af4cba0ce970ab40",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d8f7208d4b1346cbb7dac183cabb2d21",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8aeab9c12da94501bf0c8d9b636344ab",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of  SentenceTransformer(\n",
            "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel \n",
            "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
            "  (2): Normalize()\n",
            ") is:  30.0 %.\n",
            "Accuracy of  SentenceTransformer(\n",
            "  (0): Transformer({'max_seq_length': 384, 'do_lower_case': False}) with Transformer model: MPNetModel \n",
            "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
            "  (2): Normalize()\n",
            ") is:  30.0 %.\n",
            "Accuracy of  SentenceTransformer(\n",
            "  (0): Transformer({'max_seq_length': 128, 'do_lower_case': False}) with Transformer model: BertModel \n",
            "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
            ") is:  31.0 %.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at sentence-transformers/use-cmlm-multilingual were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of  SentenceTransformer(\n",
            "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel \n",
            "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
            "  (2): Normalize()\n",
            ") is:  30.0 %.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ee6c461f3b8441d39a61f0eb3e56243f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7747fc309bcb4d9483c0380e81e30335",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c0b128458d2f47589f7d665151d999e7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md:   0%|          | 0.00/3.51k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d5951c9014d74fe4a32b2d45e543d552",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "720a006a788f4f2dabb7e82a72ed4012",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fb76d7fbf1294b2cb3af7b0fc93a6001",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e4c3ddcf6c8f4533a08c9ac37af38644",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/314 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "df578dca31d84e18995960fbbd65bf0b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6cd99799c9944315934c13e96ae59e97",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9e65ae1dd826457f9255e7339c896a8d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0f1f4a13e9ec49c4b367fb09c6d55eee",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of  SentenceTransformer(\n",
            "  (0): Transformer({'max_seq_length': 128, 'do_lower_case': False}) with Transformer model: BertModel \n",
            "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
            ") is:  31.0 %.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "82e8d098981f4443952c32586a08106d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "65174ecb09db43c9bc8fa83e216d8742",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8be4f3b86bd74c4d9a28b908505c0899",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md:   0%|          | 0.00/3.90k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dd999ea186064edaab9940a18d40abf6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "afbd70e6d5e44843bdcd043d9e3341fc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/723 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c1ec8ceafae14c3891594e447d22c432",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.11G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3fb2b4309beb45ef9f7ef9f3a2c00847",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/402 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f0910d21c6834fe3a39080e44dc58aff",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c553162f9ff1406f973ffc69d9fb17c7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/9.08M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1291ad86f4234b76b2298f31d31a8939",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5ab0b6b49a9b4f7f94709f05d36d1573",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of  SentenceTransformer(\n",
            "  (0): Transformer({'max_seq_length': 128, 'do_lower_case': False}) with Transformer model: XLMRobertaModel \n",
            "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
            ") is:  31.0 %.\n"
          ]
        }
      ],
      "source": [
        "# function for optimal correct answers & semantic similarity\n",
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline(\"zero-shot-classification\",model=\"facebook/bart-large-mnli\", hypothesis_template=\"{}\")\n",
        "\n",
        "for smodel in similarity_models:\n",
        "    correct = 0\n",
        "\n",
        "    model = SentenceTransformer(smodel)\n",
        "\n",
        "\n",
        "    for idx in range(100):\n",
        "        sentence = similarity_ds['question'][idx]\n",
        "        sentence1 = similarity_ds['correct1'][idx]\n",
        "        sentence2 = similarity_ds['correct2'][idx]\n",
        "        best = similarity_ds['best'][idx]\n",
        "        incorrect = similarity_ds['incorrect'][idx]\n",
        "\n",
        "        candidate_labels = [best, sentence1, sentence2, incorrect]\n",
        "\n",
        "        prediction = classifier(sentence, candidate_labels)\n",
        "        selected = prediction['labels'][0]\n",
        "        embeddings = model.encode([best, selected], convert_to_tensor=True)\n",
        "\n",
        "\n",
        "        sim = get_cosine_similarity(embeddings[0], embeddings[1])\n",
        "\n",
        "        if selected in (sentence1, sentence2) and sim > 0.95:\n",
        "            correct += 1\n",
        "\n",
        "    accuracy = correct / 100\n",
        "    print(\"Accuracy of \", model, \"is: \", accuracy * 100, \"%.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQATbpGyeByP"
      },
      "source": [
        "## Β3. Winogrande dataset\n",
        "\n",
        "Το [Winogrande dataset](https://huggingface.co/datasets/winogrande) αποτελείται από προτάσεις που μία λέξη τους έχει αφαιρεθεί και δίνονται δύο πιθανές επιλογές συμπλήρωσης του κενού. Για παράδειγμα, δοθείσας της πρότασης \"John moved the couch from the garage to the backyard to create space. The _ is small.\", υπάρχουν δύο πιθανές εναλλακτικές:\n",
        "\n",
        "- \"garage\"\n",
        "- \"backyard\"\n",
        "\n",
        "Η δυσκολία της συμπλήρωσης έγκειται στο ότι και οι δύο λέξεις αναφέρονται στην πρόταση, οπότε το μοντέλο θα πρέπει να διαθέτει υψηλές δυνατότητες κατανόησης γλώσσας προκειμένου να επιλέξει μια νοηματικά σωστή συμπλήρωση.\n",
        "\n",
        "Για λόγους επιτάχυνσης, επιλέγουμε ένα τυχαίο υποσύνολο 100 δειγμάτων από το training set του Winogrande.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214,
          "referenced_widgets": [
            "9ba5051a2ec241d3a7890c80f32e8a19",
            "122f3471eb3b463c9721a856d6a20af6",
            "3af6dffbf97c4b1daeb6a6e31760b134",
            "f5548ae5ab774ff987e8cab0bfd97ced",
            "de4bdf7cfcf445a0a9fc45d285d558b0",
            "a0cbb2250fe945c9a8f77d929b680147",
            "976a2eda3b384974bcc64801ac86cf32",
            "ef128325346f461baf7e1b1a43dbbcee",
            "617e8ac15f604cc2adb47a7c6e1246b8",
            "10f72352fa58465fbafd73d2c3e1fd73",
            "c45e195daffd42e3b9503718be010c94",
            "42bb541e96db4e39a3b78f683546b5b0",
            "f80562fbab5f46b58de9562cf1473844",
            "1a3dbf1180f64fd89428592259f6fb5d",
            "7af477f76eb34350a563f2260275a6de",
            "a19c22240cf942159c256dfbb554b1c3",
            "740d20aa33bb4fa49e02085cb56a5d56",
            "ce6dc29b6d7740d99ee04008407d1a82",
            "d058b202fd454a3d822adb39e6a41f09",
            "0e35289b3e424ecd9f21ebf923188987",
            "30ae9eebf51b488489c7e11a67a3e738",
            "ab61b9696fb34262891af7d520a9d691",
            "2c0a7b43e7a5429c9a54988afcc03e01",
            "ef1d3cc06cd546769aad488f318b3941",
            "fb3bab60b1de40c6b4d11799a967d767",
            "c810f9c2d9fb4742ae5a21a41be6b18c",
            "a59a3d8e603941d4b772ad25de21989a",
            "7b65cc91bdbc4d4c91366787d9f1de61",
            "d44d6b37138f471897adc328e08550ca",
            "4ac518d6560948ab9527f98ce0c1fae9",
            "0cd3befd2ce24180a22c873d7b6ea3fa",
            "195e2a63c3054d70b5e04e48bd55290c",
            "ed569cbfb28d453aaba45b34aa641a4e",
            "e769bf8109a440af953cb2c7f6e78d16",
            "112623dc1a944157ad289c9a32c659e8",
            "f51a4bd686d843899b41b398d0a167b4",
            "0c50253f181640499e189f25e9a59708",
            "0acc5251f67d4bbe94d714e655c84821",
            "598ae3bc50c6406bb6c43aee0add0d9f",
            "7318cbd65ce84acca94e2b6dfe85f3ac",
            "a6c72fc40a3c4c0d8de2c2b162be3efa",
            "aea8eccb53b344b0bac296fa1c37bfb7",
            "083ddb8499e34d8eabae18e23689f830",
            "627aaa3870fc48bb991ded1785e64825"
          ]
        },
        "id": "s-Jkr97igAJO",
        "outputId": "e1de6476-a13f-4319-be98-e04c14afddf7"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9ba5051a2ec241d3a7890c80f32e8a19",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data:   0%|          | 0.00/3.40M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "42bb541e96db4e39a3b78f683546b5b0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/160 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2c0a7b43e7a5429c9a54988afcc03e01",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating test split:   0%|          | 0/1767 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e769bf8109a440af953cb2c7f6e78d16",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating validation split:   0%|          | 0/1267 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['sentence', 'option1', 'option2', 'answer'],\n",
              "    num_rows: 100\n",
              "})"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# load dataset\n",
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"winogrande\", 'winogrande_xs')\n",
        "train_ds = dataset[\"train\"]\n",
        "train_ds = train_ds.select(range(100))\n",
        "\n",
        "train_ds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpuR6PbVmwbd"
      },
      "source": [
        "Με κατάλληλο [μετασχηματισμό](https://huggingface.co/DeepPavlov/roberta-large-winogrande) της παραπάνω εισόδου (πρόταση με κενό και δύο επιλογές συμπλήρωσης), θα καταγράψουμε το accuracy σχετικών μοντέλων που επιλύουν το πρόβλημα, συγκρίνοντας το predicted label με το πραγματικό label (1: πρώτη επιλογή, 2: δεύτερη επιλογή). Ουσιαστικά θα πρέπει να ανάγουμε το παραπάνω πρόβλημα σε κάποιο πιο κλασικό πρόβλημα της επεξεργασίας φυσικής γλώσσας.\n",
        "\n",
        "Δοκιμάζουμε  3 κατάλληλα μοντέλα από το Huggingface για να προσεγγίζουμε το πρόβλημα του Winogrande."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m1oZcCm2c29U"
      },
      "outputs": [],
      "source": [
        "# load models\n",
        "models = [\n",
        "    \"bert-base-uncased\",\n",
        "    \"albert-base-v2\",\n",
        "    \"roberta-base\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 809,
          "referenced_widgets": [
            "86cafd2fac514cfd9fa8c13190fda808",
            "921ef067e1c44042a40eaab6ee811162",
            "198a480545bf46d9a4143ac9bf495eee",
            "20a87978f796437c9fb0e1e89866c0c9",
            "5d0439f47d7645bb811fb34ba7e7b4bf",
            "3a83d0b9e37144baa23fd4fd400a0864",
            "162e3911db6a455986d5053d3fd7c814",
            "5cbbd295ac74460685f1a93779e21410",
            "5a99cc989c6f40ac9105f26fb27fe879",
            "9ea1874f7d874daea519daf603a41c38",
            "1012b37aaafd4e968c121cf5c29bed6d",
            "e2503b3bc6494e62a4bb76f556681fa0",
            "299d1cb1e41e4f1ab1e3dc00ce9fb4ee",
            "676fad8b098549a09bac6219fbd599a1",
            "a0cdb7965a8542e58dd8435312d767b6",
            "63a81d9ffad649ae9239b3731dc55817",
            "5edac78f04494dd7943570826084d129",
            "4fe86f14094b429b855478b60d87aa08",
            "0f041add4c5a4ba9825cb459b9b7867f",
            "5f6e830b72a84dffbcef8f35d6c96397",
            "24f1b36314f24596835a0e5903dd8157",
            "af38036bd86641e8bd4f8a2208410bff",
            "84323943056c45b0904a24cbc0610e47",
            "d06fe096ecac4ab4985cde9ff6d69721",
            "08e9fc3c0fa64c2993d09c9202fcf0f5",
            "9bee0ac12e1345a088cd07e245023f77",
            "722096c7938042299107c1618060d9f3",
            "30e0e125881949ca9a096c9efa21cf67",
            "382efffca1db47239ef476624249e958",
            "fecb7ab00abb43f097dc671a32d55fd0",
            "d1cc81439c594a50a53e7649790080bc",
            "bdc2d6b9f65e4e6eb554fb92cc561f37",
            "3ae5904788c149bead5f6a31fde7d945",
            "01271b357d2b4800b38c6fe55669b67b",
            "dc9eb91e95564950a4b35e74ab1730ea",
            "67983e970456454a80b791153e77eebf",
            "51fdf66a96b243e09e2d094e8ba262c2",
            "5b9cf181e9284b68afddf2cd3c4b5274",
            "334cbfd35e6a41d9bab7b71ee8184b0a",
            "8791fcc709044875a8445169c6e3c5f9",
            "8fc5cd42f22e4b0ca2e10c63ea56a88b",
            "11b801daf3304f99a8896826c8c380c5",
            "0c4c100424274553be21da9388c50a6c",
            "5aeecf4945164f6783b3455d69c00e53",
            "458543a8da97467683e6b3dc0061a3ce",
            "27fa01e6c97245c5817264252f8bbd25",
            "5ae97217960445138c137d93a13b9d4e",
            "24b332b1ede243cbbdb825208af33180",
            "b1ce9a992f274576b58a12ad86e167ff",
            "b5a1df1130864cba9e9c71eb32f76672",
            "b24d6e6f76974c74849a610217a0c8b7",
            "2bbed7f53e7b46feaef82025ff451436",
            "6335e0c125b84c3d945aec39dbbbe5c9",
            "b8fbb48978ae4277a603216dcd5f92a9",
            "db8eacae77a740d0b5a8d4a9b84c829e",
            "3a0e91ba5b164d58907ed4a65a32fbf7",
            "6ab7b1d0d65f4ea395837dcf6fb40f5e",
            "07031a5adb60414bac7155083641a68c",
            "7eeeea1e15f0470ab6722243148f1289",
            "373ae05e74744d16a4e572ac46ad18aa",
            "6eddeb3c80304bf4a5a9b6f17eef747f",
            "ab745c7bc6a54b13b7e4c6042a1dfd72",
            "19486b7818bb4ee1b6e125571f51632e",
            "f61fbad730344a28b2cc44883e242e8c",
            "cb51f7e646454416b8b01b9009b41905",
            "0c1860bcef3141e583fb30efe2768b57",
            "164c8c652f3542c4bf62f8d468e43e33",
            "0875ae68b0ea484ca4d7b80ca4562c1c",
            "4d859cad3f1345c7836f2186ce08ccff",
            "d2f7f9c69b1c4bcaac3aee3150b2a3fb",
            "23bc6aef277846c2a7b66ef97fbda78f",
            "776aac9dcc4b4172b63b85bf3c2c6ff3",
            "d98efdde3d28446e83917d5ded1a9bbf",
            "e2ad5accffd9455cbb6168b678b27376",
            "d4b248ef21254dfa839d54eaced17134",
            "a1f0e2673ab34bbabdade0540ea5e334",
            "e561608fe5d646c3864c787e1beb1611",
            "3c0c37b939904142b96b8ea4a06caa6c",
            "6c150ccfb33e4e38998c55de7b03a508",
            "d879a8f59f73478a8d7423325e46ab94",
            "c780199b50ba49f1b04ccba5add05d18",
            "e4d163ff0f8246e0b212ac881441f9b5",
            "a988390bc58c468a831d8850821671f5",
            "3263353f4fae4b1f863fd7e8e5c5a0b6",
            "bb85d2075a104e3a8ad11fba7bfcc639",
            "559baf3eb85b468abb01ba730f03088e",
            "3f59ece47a264e7b8d4eeba3fffdb113",
            "d12310a994be4b41af93c33b1d4adc1e",
            "8f61bb9dc3dc450b9b116e223d89b9ef",
            "739622e6f1e642b185560719b5b4f989",
            "c0ce9c27b6ab45268adadc676300dd0a",
            "fe25afa0f10449b6ae54ddd66c468c79",
            "a417a225044b4eeea81dcc9fc5816c55",
            "e4db9bd4abf341d4b90e1fdf8ee258d4",
            "4947b5bdbc8e4640b9df64a34c44c36f",
            "bb2062e6b2a84703bbcd7159cf0a5864",
            "3a8de0d72a8d4f8db477c25d8cdee144",
            "fd67b8a9791c4edb8873ab29e9e074cd",
            "3ad8802567fb424296c8b797e644fe4b",
            "a09d4b549df342f482c6b4e4bfcc7145",
            "0f989b8562b042adadfc4e8c6c9771ed",
            "ecffcd8e52284d52ae5a3d3304a10560",
            "e55184b283944758bec712cc8f71cec8",
            "9170c9d1c4bb40afb9d05d8ff8a83253",
            "008fde68199845b2821f936d62b62fd4",
            "0c2b62a62866472a8ebeaf2d101c43d4",
            "4c611183c23642d7b1b3789e6160c25d",
            "8930010a94804d24aab16fe3e32ce988",
            "84c040a39d1d4f1fb9ee4593ca5999a3",
            "0da17e51638744e5ac0fa3b50c7ed644",
            "204ac56be87e43798356da7d1f376c16",
            "9e92fe5e0e054002aa2007835421c7f8",
            "2799e4537abf4875916d14673b72267f",
            "6cbc0893e0024fc2bd64e47494abc7c7",
            "6d0ba5922ce94b2c8e31c78a41dea2b3",
            "34dc259e91a94579ac798438f86f89bf",
            "13829d9954e04259b49cf826178fee25",
            "fcc8923d9e394fa39d0f64c019c27bd4",
            "d0e3d6714c394e3a942274d6cb50442f",
            "8e5bfc5201904bf4a97170984e8c8589",
            "fce12201c943494d870a3da9bb77a16b",
            "2c05150085a54a9e9a8f650876f97239",
            "0cc8ec4314ef4d06894933ef126b5a9a",
            "61cf53d0dcdc42df83f2543541d3b598",
            "8e940c91ac054c8e838ec24eb8063481",
            "b4e857699cfd4537ae4717730f574036",
            "258428b9da9842d6a9693e412a53c3e8",
            "57cf68b2ec394accb3bb4b2b138773b1",
            "d85866f77e814c3781088f349791eb4c",
            "abf441a77a334431b60d859b5a0af05c",
            "6d31c2d650264161bb517b66ea202d47",
            "7906388eb62a4b7681560be4fc5fce59",
            "9d72716c0522419d94df1b29fe91d263",
            "61c37c53f1824801a67dab18bb6807d1",
            "c430084c97534e7fa00e4e5a6797fc12",
            "e6cf492fee8e418aa7f2556c54c8bb90",
            "0436e024dcc7477a8659b7eb1de9e8aa",
            "0a9af8fbd22b4a8a99c49bcbbea7da95",
            "c183d00184d84a12821dff8c94019273",
            "0427d2ab9d0d4238b8ab161699cacc05",
            "5e3a1d4f89a047a095bb23ecdd086938",
            "581a36be2e6e4e33815133cd298e72b7",
            "c3d781570720420f8c6632f0b48c79d5",
            "2ba8b3924f5042b8b3d999f433344305",
            "bc16e79786754b5f936f6fc31b20fcc5",
            "d8887da5f8e74ebdbb6e57b8d36a35ce",
            "aca3b0c56589480fbe3681982ae213cf",
            "2ee0780696e74c5d879e2b4004f7991d",
            "69eab6885a884378b83c46fade654668",
            "998aa199a97447e59c7ce95631600b00",
            "365ec89d8598475f8a40984754bceb8d",
            "44cf464e7a5e4b5fbba9025b4fea171c",
            "f00948c666ab4328a9266b4a9ea3cc04",
            "8dcb99e742d84e95886afb5a3c6db170",
            "d0b910b249ce4ad4b926928d6f65aac4",
            "a9f71cd356e14803b5fe82e66b806d7e",
            "0e9fc0700fdb4ceaab7f08549d47dc86",
            "d2ed6ddd038a4e8780c78ee1f3c5459b",
            "e7989ec6754a461099391aef291a655d",
            "79cf092e69db4884a0f1d545b7be3a01",
            "dd429c28cf854dab9e998f245c653eb6",
            "71867ec5479b45448b8cc8d8299512b4",
            "2b1cd20ad9f345b6875e1959594d8b6f",
            "63b5483ba0194e1084b9540e67ac3f18",
            "8a9666b81e574b76a75fd7f02dfc1654",
            "295c1c982b15403c9092263802bb9656",
            "de942394776a4b20a94a7694333201c0",
            "b43bee0e340947a796cd1132f396c46a",
            "a0c77df1d89a469592fd775b79fcbab7",
            "6ce3e77960294f44a5e0230ebae8ff1c",
            "c706ab3d9da94c73be1b5fdf6c0ca7bf",
            "9ab16b2714624f33a064c02f9c134915",
            "3ee61a8ffd8c4cbda2c5283d08ee2c5a",
            "bc955c4e66cb47e2ab30421916e9b886",
            "7c40be26e23349f5b65d8c68cc3a5731",
            "6445a013000b4edaa8c9426ae0627603"
          ]
        },
        "id": "9m6akMdBuFcw",
        "outputId": "68a95b7f-ff65-480b-b776-5760a0cb1ee6"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "86cafd2fac514cfd9fa8c13190fda808",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e2503b3bc6494e62a4bb76f556681fa0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "84323943056c45b0904a24cbc0610e47",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "01271b357d2b4800b38c6fe55669b67b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "458543a8da97467683e6b3dc0061a3ce",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3a0e91ba5b164d58907ed4a65a32fbf7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/684 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "164c8c652f3542c4bf62f8d468e43e33",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/47.4M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at albert-base-v2 were not used when initializing AlbertForMaskedLM: ['albert.pooler.bias', 'albert.pooler.weight']\n",
            "- This IS expected if you are initializing AlbertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing AlbertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3c0c37b939904142b96b8ea4a06caa6c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8f61bb9dc3dc450b9b116e223d89b9ef",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "spiece.model:   0%|          | 0.00/760k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a09d4b549df342f482c6b4e4bfcc7145",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.31M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "204ac56be87e43798356da7d1f376c16",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2c05150085a54a9e9a8f650876f97239",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9d72716c0522419d94df1b29fe91d263",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2ba8b3924f5042b8b3d999f433344305",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d0b910b249ce4ad4b926928d6f65aac4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "295c1c982b15403c9092263802bb9656",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cpu\n"
          ]
        }
      ],
      "source": [
        "# create pipelines\n",
        "from transformers import pipeline\n",
        "\n",
        "pipelines = {}\n",
        "for model in models:\n",
        "  pipelines[model] = pipeline(\"fill-mask\", model=model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PR6sz6xug_7N",
        "outputId": "f69cda9a-6099-4e9a-d693-9649c3c2a8b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of  bert-base-uncased is:  56.17977528089888 %.\n",
            "Accuracy of  albert-base-v2 is:  53.48837209302325 %.\n",
            "Accuracy of  roberta-base is:  57.446808510638306 %.\n"
          ]
        }
      ],
      "source": [
        "# function for predicting best fill\n",
        "\n",
        "for model in models:\n",
        "  total_considered = 0\n",
        "  correct = 0\n",
        "\n",
        "  mask = pipelines[model].tokenizer.mask_token\n",
        "  for idx in range(100):\n",
        "    sentence = train_ds['sentence'][idx]\n",
        "\n",
        "    masked_sentence = sentence.replace(\"_\", mask)\n",
        "\n",
        "    predictions = pipelines[model](masked_sentence)\n",
        "    top_preds = [p[\"token_str\"].strip().lower() for p in predictions[:5]]\n",
        "\n",
        "    if (train_ds['option1'][idx].lower() not in top_preds) and (train_ds['option2'][idx].lower() not in top_preds):\n",
        "      continue\n",
        "    else:\n",
        "      if (train_ds['option1'][idx].lower() not in top_preds):\n",
        "        total_considered += 1\n",
        "        op1_score = 0\n",
        "        op2_index = top_preds.index(train_ds['option2'][idx].lower())\n",
        "        op2_score = predictions[op2_index]['score']\n",
        "      elif (train_ds['option2'][idx].lower() not in top_preds):\n",
        "        total_considered += 1\n",
        "        op2_score = 0\n",
        "        op1_index = top_preds.index(train_ds['option1'][idx].lower())\n",
        "        op1_score = predictions[op1_index]['score']\n",
        "      else:\n",
        "        total_considered += 1\n",
        "        op1_index = top_preds.index(train_ds['option1'][idx].lower())\n",
        "        op2_index = top_preds.index(train_ds['option2'][idx].lower())\n",
        "\n",
        "        op1_score = predictions[op1_index]['score']\n",
        "        op2_score = predictions[op2_index]['score']\n",
        "\n",
        "        predictions[op1_index]['token_str']\n",
        "        predictions[op2_index]['token_str']\n",
        "\n",
        "    if op1_score > op2_score:\n",
        "      pred = 1\n",
        "    else: pred = 2\n",
        "\n",
        "    ans = int(train_ds['answer'][idx])\n",
        "\n",
        "    if pred == ans:\n",
        "      correct += 1\n",
        "\n",
        "  accuracy = correct / total_considered\n",
        "  print(\"Accuracy of \", model, \"is: \", accuracy * 100, \"%.\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
